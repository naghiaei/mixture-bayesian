{"cells":[{"cell_type":"markdown","metadata":{"id":"OWf-0WqK9Xzt"},"source":["# Imports"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":1898,"status":"ok","timestamp":1724107144645,"user":{"displayName":"Ehsan Naghiaei","userId":"05342714995998442181"},"user_tz":420},"id":"oKfUgGsq9ZOY"},"outputs":[],"source":["import pandas as pd\n","import numpy as np\n","from tqdm import tqdm\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import ndcg_score\n","from sklearn.metrics.pairwise import cosine_similarity\n","from scipy.stats import beta\n","from scipy.optimize import minimize\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n"]},{"cell_type":"markdown","metadata":{"id":"-opNuVP7-XcA"},"source":["# Data Simulation"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":371,"status":"ok","timestamp":1724107145014,"user":{"displayName":"Ehsan Naghiaei","userId":"05342714995998442181"},"user_tz":420},"id":"YnBB0DJumGYo"},"outputs":[],"source":["\n","\n","def generate_catalog(num_movies, genres, other_attribute_values, mode='balanced', genre_weights=None, other_attr_weights=None):\n","    \"\"\"\n","    Generates a catalog of movies with specified distribution mode over given attributes.\n","\n","    Parameters:\n","    num_movies (int): Total number of movies to generate.\n","    genres (list): List of available genres.\n","    other_attribute_values (list): List of values for the other categorical attribute.\n","    mode (str): Distribution mode ('balanced', 'random', 'weighted').\n","    genre_weights (list): Weights for each genre if mode is 'weighted'.\n","    other_attr_weights (list): Weights for each other attribute value if mode is 'weighted'.\n","\n","    Returns:\n","    pd.DataFrame: DataFrame containing the movie catalog with columns 'movieID', 'genre', and 'other_attribute'.\n","    \"\"\"\n","    if mode not in ['balanced', 'random', 'weighted']:\n","        raise ValueError(\"Mode must be one of 'balanced', 'random', or 'weighted'\")\n","\n","    if mode == 'balanced':\n","        genre_count = len(genres)\n","        other_attr_count = len(other_attribute_values)\n","        movies_per_genre = num_movies // genre_count\n","        movies_per_other_attr = num_movies // other_attr_count\n","\n","        movie_list = []\n","        movie_id = 1\n","\n","        for genre in genres:\n","            for other_attr in other_attribute_values:\n","                for _ in range(num_movies // (genre_count * other_attr_count)):\n","                    movie_list.append([movie_id, genre, other_attr])\n","                    movie_id += 1\n","\n","    elif mode == 'random':\n","        movie_list = []\n","        movie_id = 1\n","\n","        for _ in range(num_movies):\n","            genre = np.random.choice(genres)\n","            other_attr = np.random.choice(other_attribute_values)\n","            movie_list.append([movie_id, genre, other_attr])\n","            movie_id += 1\n","\n","    elif mode == 'weighted':\n","        if genre_weights is None or other_attr_weights is None:\n","            raise ValueError(\"Weights must be provided for 'weighted' mode\")\n","        if len(genre_weights) != len(genres) or len(other_attr_weights) != len(other_attribute_values):\n","            raise ValueError(\"Length of weights must match length of genres and other attributes\")\n","\n","        movie_list = []\n","        movie_id = 1\n","\n","        genre_prob = np.array(genre_weights) / np.sum(genre_weights)\n","        other_attr_prob = np.array(other_attr_weights) / np.sum(other_attr_weights)\n","\n","        for _ in range(num_movies):\n","            genre = np.random.choice(genres, p=genre_prob)\n","            other_attr = np.random.choice(other_attribute_values, p=other_attr_prob)\n","            movie_list.append([movie_id, genre, other_attr])\n","            movie_id += 1\n","\n","    movie_df = pd.DataFrame(movie_list, columns=['movieID', 'genre', 'other_attribute'])\n","\n","    return movie_df\n","\n","# # Example Usage\n","# num_movies = 1000\n","# genres = ['comedy', 'drama', 'action', 'thriller']\n","# other_attribute_values = ['actor1', 'actor2', 'actor3', 'actor4']\n","# genre_weights = [0.1, 0.2, 0.4, 0.3]\n","# other_attr_weights = [0.25, 0.25, 0.25, 0.25]\n","\n","# # Balanced mode\n","# balanced_catalog = generate_catalog(num_movies, genres, other_attribute_values, mode='balanced')\n","# print(\"Balanced Catalog:\\n\", balanced_catalog.head())\n","\n","# # Random mode\n","# random_catalog = generate_catalog(num_movies, genres, other_attribute_values, mode='random')\n","# print(\"\\nRandom Catalog:\\n\", random_catalog.head())\n","\n","# # Weighted mode\n","# weighted_catalog = generate_catalog(num_movies, genres, other_attribute_values, mode='weighted', genre_weights=genre_weights, other_attr_weights=other_attr_weights)\n","# print(\"\\nWeighted Catalog:\\n\", weighted_catalog.head())\n"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":265,"status":"ok","timestamp":1724107162606,"user":{"displayName":"Ehsan Naghiaei","userId":"05342714995998442181"},"user_tz":420},"id":"eeHbqocBpsxg"},"outputs":[],"source":["def generate_users_behavior(num_users, genres, other_attribute_values):\n","    \"\"\"\n","    Generates user behavior by assigning a preference order and value function parameters.\n","\n","    Parameters:\n","    num_users (int): Total number of users to generate.\n","    genres (list): List of available genres.\n","    other_attribute_values (list): List of values for the other categorical attribute.\n","\n","    Returns:\n","    pd.DataFrame: DataFrame containing user behaviors with columns 'userID', 'genre_pref', 'other_attr_pref', 'alpha', 'beta'.\n","    \"\"\"\n","    user_list = []\n","    np.random.seed(42)  # For reproducibility\n","\n","    for user_id in range(1, num_users + 1):\n","        genre_pref = np.random.permutation(genres).tolist()\n","        other_attr_pref = np.random.permutation(other_attribute_values).tolist()\n","        alpha = np.random.random()  # Random alpha parameter for Cobb-Douglas function\n","        beta = 1 - alpha  # Ensuring alpha + beta = 1 for Cobb-Douglas function\n","\n","        user_list.append([user_id, genre_pref, other_attr_pref, alpha, beta])\n","\n","    user_df = pd.DataFrame(user_list, columns=['userID', 'genre_pref', 'other_attr_pref', 'alpha', 'beta'])\n","\n","    return user_df"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":1,"status":"ok","timestamp":1724107162606,"user":{"displayName":"Ehsan Naghiaei","userId":"05342714995998442181"},"user_tz":420},"id":"oQMiiik7qX-d"},"outputs":[],"source":["def generate_ratings(num_ratings, user_df, movie_df, randomness=0.0):\n","    \"\"\"\n","    Generates ratings for users based on their preferences and the movie catalog with added randomness.\n","\n","    Parameters:\n","    num_ratings (int): Number of ratings to generate per user.\n","    user_df (pd.DataFrame): DataFrame containing user behaviors.\n","    movie_df (pd.DataFrame): DataFrame containing the movie catalog.\n","    randomness (float): Degree of randomness in assigned ratings. 0 means no randomness, 1 means fully random.\n","\n","    Returns:\n","    pd.DataFrame: DataFrame containing the ratings with columns 'userID', 'movieID', 'rating'.\n","    \"\"\"\n","    ratings_list = []\n","\n","    for _, user in user_df.iterrows():\n","        user_id = user['userID']\n","        genre_pref = user['genre_pref']\n","        other_attr_pref = user['other_attr_pref']\n","        alpha = user['alpha']\n","        beta = user['beta']\n","\n","        sampled_movies = movie_df.sample(n=num_ratings, replace=False)\n","\n","        for _, movie in sampled_movies.iterrows():\n","            movie_id = movie['movieID']\n","            genre = movie['genre']\n","            other_attr = movie['other_attribute']\n","\n","            # Determine the value based on user's preference order\n","            genre_value = (len(genre_pref) - genre_pref.index(genre)) / len(genre_pref)\n","            other_attr_value = (len(other_attr_pref) - other_attr_pref.index(other_attr)) / len(other_attr_pref)\n","\n","            # Cobb-Douglas value function\n","            value = (genre_value ** alpha) * (other_attr_value ** beta)\n","\n","            # Introduce randomness\n","            if np.random.rand() < randomness:\n","                value = np.random.random()  # Assign a random value\n","\n","            ratings_list.append([user_id, movie_id, value])\n","\n","    ratings_df = pd.DataFrame(ratings_list, columns=['userID', 'movieID', 'value'])\n","\n","    # Normalize values to 1-5 scale for ratings\n","    ratings_df['rating'] = 1 + round(4 * (ratings_df['value'] - ratings_df['value'].min()) / (ratings_df['value'].max() - ratings_df['value'].min()))\n","\n","    return ratings_df[['userID', 'movieID', 'rating']]"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":3,"status":"ok","timestamp":1724107164010,"user":{"displayName":"Ehsan Naghiaei","userId":"05342714995998442181"},"user_tz":420},"id":"uB7RqcCFZI07"},"outputs":[],"source":["\n","def generate_ratings(num_ratings, user_df, movie_df, randomness=0.0):\n","    \"\"\"\n","    Generates ratings for users based on their preferences and the movie catalog with added randomness.\n","\n","    Parameters:\n","    num_ratings (int): Number of ratings to generate per user.\n","    user_df (pd.DataFrame): DataFrame containing user behaviors.\n","    movie_df (pd.DataFrame): DataFrame containing the movie catalog.\n","    randomness (float): Degree of randomness in assigned ratings. 0 means no randomness, 1 means fully random.\n","\n","    Returns:\n","    pd.DataFrame: DataFrame containing the ratings with columns 'userID', 'movieID', 'rating'.\n","    \"\"\"\n","    ratings_list = []\n","\n","    for _, user in user_df.iterrows():\n","        user_id = user['userID']\n","        genre_pref_consistent = user['genre_pref']\n","        other_attr_pref_consistent = user['other_attr_pref']\n","        alpha = user['alpha']\n","        beta = user['beta']\n","\n","        # Generate inconsistent preferences by shuffling the consistent preferences\n","        genre_pref_inconsistent = genre_pref_consistent.copy()\n","        other_attr_pref_inconsistent = other_attr_pref_consistent.copy()\n","        np.random.shuffle(genre_pref_inconsistent)\n","        np.random.shuffle(other_attr_pref_inconsistent)\n","\n","        sampled_movies = movie_df.sample(n=num_ratings, replace=False)\n","\n","        for _, movie in sampled_movies.iterrows():\n","            movie_id = movie['movieID']\n","            genre = movie['genre']\n","            other_attr = movie['other_attribute']\n","\n","            # Decide whether to use consistent or inconsistent preferences\n","            if np.random.rand() < randomness:\n","                genre_pref = genre_pref_inconsistent\n","                other_attr_pref = other_attr_pref_inconsistent\n","            else:\n","                genre_pref = genre_pref_consistent\n","                other_attr_pref = other_attr_pref_consistent\n","\n","            # Determine the value based on user's preference order\n","            genre_value = (len(genre_pref) - genre_pref.index(genre)) / len(genre_pref)\n","            other_attr_value = (len(other_attr_pref) - other_attr_pref.index(other_attr)) / len(other_attr_pref)\n","\n","            # Cobb-Douglas value function\n","            value = (genre_value ** alpha) * (other_attr_value ** beta)\n","\n","            ratings_list.append([user_id, movie_id, value])\n","\n","    ratings_df = pd.DataFrame(ratings_list, columns=['userID', 'movieID', 'value'])\n","\n","    # Normalize values to 1-5 scale for ratings\n","    ratings_df['rating'] = 1 + round(4 * (ratings_df['value'] - ratings_df['value'].min()) / (ratings_df['value'].max() - ratings_df['value'].min()))\n","\n","    return ratings_df[['userID', 'movieID', 'rating']]\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2445,"status":"ok","timestamp":1724107166453,"user":{"displayName":"Ehsan Naghiaei","userId":"05342714995998442181"},"user_tz":420},"id":"PLKra0m-qds_","outputId":"d43e6c5f-89a5-477d-dfa2-2ee1d0448dfb"},"outputs":[],"source":["# Parameters\n","num_movies = 200\n","num_users = 1000\n","num_ratings_per_user = 50\n","genres = ['comedy', 'drama', 'action', 'romance']\n","lead_actors = ['actor1', 'actor2', 'actor3', 'actor4']\n","\n","# Generate catalog and users behavior\n","movie_catalog = generate_catalog(num_movies, genres, lead_actors)\n","user_behavior = generate_users_behavior(num_users, genres, lead_actors)\n","\n","# Generate ratings\n","ratings_df = generate_ratings(num_ratings_per_user, user_behavior, movie_catalog)\n","\n","print(ratings_df.head())\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":424},"executionInfo":{"elapsed":4,"status":"ok","timestamp":1724107166453,"user":{"displayName":"Ehsan Naghiaei","userId":"05342714995998442181"},"user_tz":420},"id":"FgkDlQ71qkSa","outputId":"e9a101e2-ba8d-48ce-e895-58c910608fee"},"outputs":[],"source":["movie_catalog"]},{"cell_type":"markdown","metadata":{"id":"CWI3cbBG-U-9"},"source":["# Data Pre-process"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":4,"status":"ok","timestamp":1724107166454,"user":{"displayName":"Ehsan Naghiaei","userId":"05342714995998442181"},"user_tz":420},"id":"ujx9vA7AqxlA"},"outputs":[],"source":["def convert_to_binary_ratings(rating_df):\n","    \"\"\"\n","    Converts numerical ratings to binary likes/dislikes based on the global mean rating.\n","\n","    Parameters:\n","    rating_df (pd.DataFrame): DataFrame containing user ratings with columns 'userID', 'movieID', 'rating'.\n","\n","    Returns:\n","    pd.DataFrame: DataFrame with binary ratings.\n","    \"\"\"\n","    global_mean = rating_df['rating'].mean()\n","    rating_df['like'] = (rating_df['rating'] > global_mean).astype(int)\n","    return rating_df\n","\n","def split_train_test(rating_df, test_size=0.2):\n","    \"\"\"\n","    Splits the ratings DataFrame into training and testing sets.\n","\n","    Parameters:\n","    rating_df (pd.DataFrame): DataFrame containing user ratings.\n","    test_size (float): Proportion of the dataset to include in the test split.\n","\n","    Returns:\n","    tuple: Training and testing DataFrames.\n","    \"\"\"\n","    train_df, test_df = train_test_split(rating_df, test_size=test_size, random_state=42)\n","    return train_df, test_df"]},{"cell_type":"markdown","metadata":{"id":"BVY8IIt3-dju"},"source":["# Simple Bayesian"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":588,"status":"ok","timestamp":1724107167555,"user":{"displayName":"Ehsan Naghiaei","userId":"05342714995998442181"},"user_tz":420},"id":"Ezcx1sGGy0bw"},"outputs":[],"source":["class BayesianRecommendationModel:\n","    def __init__(self, rating_df, movie_df, attributes):\n","        \"\"\"\n","        Initializes the Bayesian recommendation model.\n","\n","        Parameters:\n","        rating_df (pd.DataFrame): DataFrame containing user ratings with columns 'userID', 'movieID', 'like'.\n","        movie_df (pd.DataFrame): DataFrame containing movie attributes with columns 'movieID', and attribute columns.\n","        attributes (list): List of attribute columns to consider (e.g., ['genre', 'lead_actor']).\n","        \"\"\"\n","        self.rating_df = rating_df\n","        self.movie_df = movie_df\n","        self.attributes = attributes\n","        self.alpha = {}\n","        self.beta = {}\n","        self.attr_index_map = {}\n","        self.initialize_parameters()\n","\n","    def initialize_parameters(self):\n","        \"\"\"\n","        Initializes the alpha and beta parameters for each user-attribute pair.\n","        \"\"\"\n","        users = self.rating_df['userID'].unique()\n","        for user in tqdm(users, desc=\"Initializing parameters\"):\n","            self.alpha[user] = {attr: {val: 1 for val in self.movie_df[attr].unique()} for attr in self.attributes}\n","            self.beta[user] = {attr: {val: 1 for val in self.movie_df[attr].unique()} for attr in self.attributes}\n","\n","        # Create mappings for attribute values to indices\n","        for attr in self.attributes:\n","            self.attr_index_map[attr] = {val: idx for idx, val in enumerate(self.movie_df[attr].unique())}\n","\n","    def update_parameters(self, train_df):\n","        \"\"\"\n","        Updates the alpha and beta parameters based on the training data.\n","\n","        Parameters:\n","        train_df (pd.DataFrame): Training DataFrame with binary ratings.\n","        \"\"\"\n","        users = train_df['userID'].unique()\n","        for user in tqdm(users, desc=\"Updating parameters\"):\n","            user_ratings = train_df[train_df['userID'] == user]\n","            for attr in self.attributes:\n","                attr_values = self.movie_df.set_index('movieID').loc[user_ratings['movieID'], attr].values\n","                like_indices = user_ratings['like'].values == 1\n","                dislike_indices = user_ratings['like'].values == 0\n","\n","                for val in self.attr_index_map[attr]:\n","                    val_indices = attr_values == val\n","                    self.alpha[user][attr][val] += val_indices[like_indices].sum()\n","                    self.beta[user][attr][val] += val_indices[dislike_indices].sum()\n","\n","    def recommend(self, user_id, k=10):\n","        \"\"\"\n","        Recommends K movies for a given user.\n","\n","        Parameters:\n","        user_id (int): The user ID for whom to generate recommendations.\n","        k (int): Number of recommendations to generate.\n","\n","        Returns:\n","        pd.DataFrame: DataFrame containing recommended movieIDs as a list for the given user.\n","        \"\"\"\n","        user_alpha = self.alpha[user_id]\n","        user_beta = self.beta[user_id]\n","\n","        attr_scores = {}\n","        for attr in self.attributes:\n","            attr_scores[attr] = {val: user_alpha[attr][val] / (user_alpha[attr][val] + user_beta[attr][val])\n","                                 for val in user_alpha[attr]}\n","\n","        # Filter out movies the user has already rated\n","        seen_movies = self.rating_df[self.rating_df['userID'] == user_id]['movieID'].unique()\n","        unseen_movies = self.movie_df[~self.movie_df['movieID'].isin(seen_movies)]\n","\n","        movie_scores = np.ones(len(unseen_movies))\n","        for attr in self.attributes:\n","            movie_attr_values = unseen_movies[attr].map(attr_scores[attr]).values\n","            movie_scores *= movie_attr_values\n","\n","        top_k_indices = np.argsort(movie_scores)[-k:][::-1]\n","        recommendations = unseen_movies.iloc[top_k_indices]['movieID'].tolist()\n","\n","        return pd.DataFrame({'userID': [user_id], 'recommended_movieIDs': [recommendations]})\n","\n","    def recommend_all_users(self, k=10):\n","        \"\"\"\n","        Recommends K movies for all users in the dataset.\n","\n","        Parameters:\n","        k (int): Number of recommendations to generate for each user.\n","\n","        Returns:\n","        pd.DataFrame: DataFrame containing userID and a list of recommended movieIDs for each user.\n","        \"\"\"\n","        recommendations_list = []\n","        for user_id in tqdm(self.rating_df['userID'].unique(), desc=\"Generating recommendations for all users\"):\n","            recommendations = self.recommend(user_id, k)\n","            recommendations_list.append(recommendations)\n","\n","        return pd.concat(recommendations_list, ignore_index=True)\n"]},{"cell_type":"markdown","metadata":{"id":"Bzy1o5Ym-f7Q"},"source":["# Simple Collaborative Filtering"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":2,"status":"ok","timestamp":1724107168213,"user":{"displayName":"Ehsan Naghiaei","userId":"05342714995998442181"},"user_tz":420},"id":"8lCIFuXT-iMd"},"outputs":[],"source":["class CollaborativeFilteringModel:\n","    def __init__(self, rating_df):\n","        \"\"\"\n","        Initializes the collaborative filtering recommendation model.\n","\n","        Parameters:\n","        rating_df (pd.DataFrame): DataFrame containing user ratings with columns 'userID', 'movieID', 'rating'.\n","        \"\"\"\n","        self.rating_df = rating_df\n","        self.user_similarity = None\n","        self.user_mean_ratings = None\n","        self.initialize_parameters()\n","\n","    def initialize_parameters(self):\n","        \"\"\"\n","        Initializes the parameters for the collaborative filtering model.\n","        \"\"\"\n","        # Create user-item matrix\n","        self.user_item_matrix = self.rating_df.pivot(index='userID', columns='movieID', values='rating').fillna(0)\n","        # Compute user similarity matrix using cosine similarity\n","        self.user_similarity = cosine_similarity(self.user_item_matrix)\n","        # Mean ratings for each user to normalize ratings\n","        self.user_mean_ratings = self.user_item_matrix.mean(axis=1)\n","\n","    def predict_rating(self, user_id, movie_id):\n","        \"\"\"\n","        Predicts the rating for a given user and movie based on collaborative filtering.\n","\n","        Parameters:\n","        user_id (int): The user ID for whom to predict the rating.\n","        movie_id (int): The movie ID for which to predict the rating.\n","\n","        Returns:\n","        float: Predicted rating.\n","        \"\"\"\n","        if movie_id not in self.user_item_matrix.columns:\n","            return self.user_mean_ratings.loc[user_id]\n","\n","        # Get the similarity scores for the target user with all other users\n","        user_index = self.user_item_matrix.index.get_loc(user_id)\n","        user_similarities = self.user_similarity[user_index]\n","\n","        # Get the ratings for the target movie by all other users\n","        movie_ratings = self.user_item_matrix[movie_id]\n","\n","        # Only consider ratings from users who have rated the target movie\n","        valid_ratings = movie_ratings != 0\n","        similarities = user_similarities[valid_ratings]\n","        ratings = movie_ratings[valid_ratings]\n","\n","        # Get the mean ratings for the valid users\n","        valid_user_indices = self.user_item_matrix.index[valid_ratings]\n","        valid_user_means = self.user_mean_ratings[valid_user_indices]\n","\n","        if similarities.sum() == 0:\n","            return self.user_mean_ratings.loc[user_id]\n","\n","        # Compute the predicted rating\n","        predicted_rating = self.user_mean_ratings.loc[user_id] + np.dot(similarities, ratings - valid_user_means) / similarities.sum()\n","\n","        return predicted_rating\n","\n","    def recommend(self, user_id, k=10):\n","        \"\"\"\n","        Recommends K movies for a given user.\n","\n","        Parameters:\n","        user_id (int): The user ID for whom to generate recommendations.\n","        k (int): Number of recommendations to generate.\n","\n","        Returns:\n","        pd.DataFrame: DataFrame containing recommended movieIDs as a list for the given user.\n","        \"\"\"\n","        seen_movies = self.user_item_matrix.loc[user_id][self.user_item_matrix.loc[user_id] > 0].index\n","        all_movies = self.user_item_matrix.columns\n","        unseen_movies = [movie for movie in all_movies if movie not in seen_movies]\n","\n","        movie_scores = [(movie, self.predict_rating(user_id, movie)) for movie in unseen_movies]\n","        movie_scores = sorted(movie_scores, key=lambda x: x[1], reverse=True)[:k]\n","\n","        recommendations = [movie for movie, score in movie_scores]\n","\n","        return pd.DataFrame({'userID': [user_id], 'recommended_movieIDs': [recommendations]})\n","\n","    def recommend_all_users(self, k=10):\n","        \"\"\"\n","        Recommends K movies for all users in the dataset.\n","\n","        Parameters:\n","        k (int): Number of recommendations to generate for each user.\n","\n","        Returns:\n","        pd.DataFrame: DataFrame containing userID and a list of recommended movieIDs for each user.\n","        \"\"\"\n","        recommendations_list = []\n","        for user_id in tqdm(self.rating_df['userID'].unique(), desc=\"Generating recommendations for all users\"):\n","            recommendations = self.recommend(user_id, k)\n","            recommendations_list.append(recommendations)\n","\n","        return pd.concat(recommendations_list, ignore_index=True)"]},{"cell_type":"markdown","metadata":{"id":"puEQP9jtVvGB"},"source":["# Multi-attribute Utility Model"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":2,"status":"ok","timestamp":1724107168874,"user":{"displayName":"Ehsan Naghiaei","userId":"05342714995998442181"},"user_tz":420},"id":"-8ZzjUf4G4w4"},"outputs":[],"source":["import numpy as np\n","import pandas as pd\n","from tqdm import tqdm\n","from scipy.optimize import minimize\n","from joblib import Parallel, delayed\n","\n","class MultiAttributeUtilityModel:\n","    def __init__(self, rating_df, movie_df, attributes):\n","        \"\"\"\n","        Initializes the Multi-Attribute Utility recommendation model.\n","\n","        Parameters:\n","        rating_df (pd.DataFrame): DataFrame containing user ratings with columns 'userID', 'movieID', 'rating'.\n","        movie_df (pd.DataFrame): DataFrame containing movie attributes with columns 'movieID', and attribute columns.\n","        attributes (list): List of attribute columns to consider (e.g., ['genre', 'lead_actor']).\n","        \"\"\"\n","        self.rating_df = rating_df\n","        self.movie_df = movie_df\n","        self.attributes = attributes\n","        self.utility_params = {}\n","        self.attr_index_map = {}\n","        self.cached_utility_values = {}\n","        self.initialize_parameters()\n","\n","    def initialize_parameters(self):\n","        \"\"\"\n","        Initializes the utility parameters for each user-attribute pair.\n","        \"\"\"\n","        users = self.rating_df['userID'].unique()\n","        for user in tqdm(users, desc=\"Initializing parameters\"):\n","            self.utility_params[user] = {\n","                attr: np.random.rand(len(self.movie_df[attr].unique()))\n","                for attr in self.attributes\n","            }\n","\n","        # Create mappings for attribute values to indices\n","        for attr in self.attributes:\n","            self.attr_index_map[attr] = {val: idx for idx, val in enumerate(self.movie_df[attr].unique())}\n","\n","    def exponential_utility(self, x, beta):\n","        \"\"\"\n","        Exponential utility function.\n","\n","        Parameters:\n","        x (float): The attribute value.\n","        beta (float): The parameter for the exponential utility function.\n","\n","        Returns:\n","        float: The utility value.\n","        \"\"\"\n","        return np.exp(beta * x)\n","\n","    def utility_function(self, movie_id, user_id):\n","        \"\"\"\n","        Computes the overall utility of a movie for a given user.\n","\n","        Parameters:\n","        movie_id (int): The movie ID.\n","        user_id (int): The user ID.\n","\n","        Returns:\n","        float: The overall utility value.\n","        \"\"\"\n","        if (movie_id, user_id) in self.cached_utility_values:\n","            return self.cached_utility_values[(movie_id, user_id)]\n","\n","        movie_attrs = self.movie_df.loc[self.movie_df['movieID'] == movie_id].iloc[0]\n","        utility = 1.0\n","        for attr in self.attributes:\n","            attr_value = movie_attrs[attr]\n","            beta = self.utility_params[user_id][attr][self.attr_index_map[attr][attr_value]]\n","            utility *= self.exponential_utility(1, beta)\n","\n","        self.cached_utility_values[(movie_id, user_id)] = utility\n","        return utility\n","\n","    def fit(self):\n","        \"\"\"\n","        Fits the model parameters using the rating data.\n","        \"\"\"\n","        def objective(beta, ratings, movie_attrs, num_attrs):\n","            predicted_ratings = np.ones(len(ratings))\n","            for i, movie in enumerate(movie_attrs):\n","                for attr in range(num_attrs):\n","                    predicted_ratings[i] *= self.exponential_utility(1, beta[attr])\n","            return np.mean((ratings - predicted_ratings) ** 2)\n","\n","        def optimize_user_params(user):\n","            user_ratings = self.rating_df[self.rating_df['userID'] == user]\n","            movie_ids = user_ratings['movieID'].values\n","            ratings = user_ratings['rating'].values\n","\n","            movie_attrs = []\n","            for movie_id in movie_ids:\n","                movie_attrs.append([self.attr_index_map[attr][self.movie_df.loc[self.movie_df['movieID'] == movie_id].iloc[0][attr]] for attr in self.attributes])\n","\n","            movie_attrs = np.array(movie_attrs)\n","\n","            initial_params = []\n","            num_attrs = len(self.attributes)\n","            for attr in self.attributes:\n","                initial_params.extend(self.utility_params[user][attr])\n","\n","            result = minimize(objective, initial_params, args=(ratings, movie_attrs, num_attrs), method='L-BFGS-B')\n","\n","            index = 0\n","            for attr in self.attributes:\n","                self.utility_params[user][attr] = result.x[index:index + len(self.utility_params[user][attr])]\n","                index += len(self.utility_params[user][attr])\n","\n","        # Use parallel processing for fitting\n","        Parallel(n_jobs=-1)(delayed(optimize_user_params)(user) for user in tqdm(self.rating_df['userID'].unique(), desc=\"Fitting parameters\"))\n","\n","    def recommend(self, user_id, k=10):\n","        \"\"\"\n","        Recommends K movies for a given user.\n","\n","        Parameters:\n","        user_id (int): The user ID for whom to generate recommendations.\n","        k (int): Number of recommendations to generate.\n","\n","        Returns:\n","        pd.DataFrame: DataFrame containing recommended movieIDs as a list for the given user.\n","        \"\"\"\n","        seen_movies = set(self.rating_df[self.rating_df['userID'] == user_id]['movieID'].unique())\n","        unseen_movies = self.movie_df[~self.movie_df['movieID'].isin(seen_movies)]\n","\n","        movie_scores = [\n","            (movie_id, self.utility_function(movie_id, user_id))\n","            for movie_id in unseen_movies['movieID'].values\n","        ]\n","        movie_scores = sorted(movie_scores, key=lambda x: x[1], reverse=True)[:k]\n","\n","        recommendations = [movie for movie, score in movie_scores]\n","        return pd.DataFrame({'userID': [user_id], 'recommended_movieIDs': [recommendations]})\n","\n","    def recommend_all_users(self, k=10):\n","        \"\"\"\n","        Recommends K movies for all users in the dataset.\n","\n","        Parameters:\n","        k (int): Number of recommendations to generate for each user.\n","\n","        Returns:\n","        pd.DataFrame: DataFrame containing userID and a list of recommended movieIDs for each user.\n","        \"\"\"\n","        recommendations_list = Parallel(n_jobs=-1)(\n","            delayed(self.recommend)(user_id, k) for user_id in tqdm(self.rating_df['userID'].unique(), desc=\"Generating recommendations for all users\")\n","        )\n","\n","        return pd.concat(recommendations_list, ignore_index=True)\n"]},{"cell_type":"markdown","metadata":{"id":"0VYKTUScEVOA"},"source":["# BPR"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":2,"status":"ok","timestamp":1724107169919,"user":{"displayName":"Ehsan Naghiaei","userId":"05342714995998442181"},"user_tz":420},"id":"aY98CheWET43"},"outputs":[],"source":["import numpy as np\n","import pandas as pd\n","from tqdm import tqdm\n","\n","class BPRModel:\n","    def __init__(self, rating_df, num_factors=10, learning_rate=0.01, regularization=0.01, iterations=100, batch_size=1000):\n","        \"\"\"\n","        Initializes the BPR model.\n","\n","        Parameters:\n","        rating_df (pd.DataFrame): DataFrame containing user ratings with columns 'userID', 'movieID', 'rating'.\n","        num_factors (int): Number of latent factors.\n","        learning_rate (float): Learning rate for SGD.\n","        regularization (float): Regularization term for preventing overfitting.\n","        iterations (int): Number of iterations for SGD.\n","        batch_size (int): Number of samples to process in each mini-batch.\n","        \"\"\"\n","        self.rating_df = rating_df\n","        self.num_factors = num_factors\n","        self.learning_rate = learning_rate\n","        self.regularization = regularization\n","        self.iterations = iterations\n","        self.batch_size = batch_size\n","        self.user_factors = None\n","        self.item_factors = None\n","        self.initialize_parameters()\n","\n","    def initialize_parameters(self):\n","        \"\"\"\n","        Initializes the latent factors for users and items.\n","        \"\"\"\n","        num_users = self.rating_df['userID'].nunique()\n","        num_items = self.rating_df['movieID'].nunique()\n","\n","        # Initialize latent factors randomly\n","        self.user_factors = np.random.normal(scale=1./self.num_factors, size=(num_users, self.num_factors))\n","        self.item_factors = np.random.normal(scale=1./self.num_factors, size=(num_items, self.num_factors))\n","\n","        # Create user and item indices for fast look-up\n","        self.user_map = {user_id: i for i, user_id in enumerate(self.rating_df['userID'].unique())}\n","        self.item_map = {item_id: i for i, item_id in enumerate(self.rating_df['movieID'].unique())}\n","        self.inverse_item_map = {i: item_id for item_id, i in self.item_map.items()}\n","\n","    def train(self):\n","        \"\"\"\n","        Trains the BPR model using mini-batch gradient descent.\n","        \"\"\"\n","        num_users = len(self.user_map)\n","        num_items = len(self.item_map)\n","\n","        # Precompute positive samples (user, item pairs)\n","        user_item_pairs = self.rating_df[['userID', 'movieID']].values\n","        user_item_pairs[:, 0] = np.array([self.user_map[x] for x in user_item_pairs[:, 0]])\n","        user_item_pairs[:, 1] = np.array([self.item_map[x] for x in user_item_pairs[:, 1]])\n","\n","        for _ in tqdm(range(self.iterations), desc=\"Training BPR model\"):\n","            # Sample mini-batch\n","            batch_indices = np.random.choice(len(user_item_pairs), self.batch_size)\n","            batch = user_item_pairs[batch_indices]\n","\n","            user_indices = batch[:, 0]\n","            positive_item_indices = batch[:, 1]\n","            negative_item_indices = np.random.choice(num_items, self.batch_size)\n","\n","            # Compute the differences in predicted scores\n","            x_uij = (\n","                np.sum(self.user_factors[user_indices] * self.item_factors[positive_item_indices], axis=1) -\n","                np.sum(self.user_factors[user_indices] * self.item_factors[negative_item_indices], axis=1)\n","            )\n","\n","            # Sigmoid function\n","            sigmoid = 1.0 / (1.0 + np.exp(x_uij))\n","\n","            # Gradients\n","            user_grad = (sigmoid[:, np.newaxis] * (self.item_factors[positive_item_indices] - self.item_factors[negative_item_indices])) - self.regularization * self.user_factors[user_indices]\n","            item_i_grad = sigmoid[:, np.newaxis] * self.user_factors[user_indices] - self.regularization * self.item_factors[positive_item_indices]\n","            item_j_grad = -sigmoid[:, np.newaxis] * self.user_factors[user_indices] - self.regularization * self.item_factors[negative_item_indices]\n","\n","            # Update latent factors\n","            self.user_factors[user_indices] += self.learning_rate * user_grad\n","            self.item_factors[positive_item_indices] += self.learning_rate * item_i_grad\n","            self.item_factors[negative_item_indices] += self.learning_rate * item_j_grad\n","\n","    def predict(self, user_id, item_id):\n","        \"\"\"\n","        Predicts the score for a given user and item.\n","\n","        Parameters:\n","        user_id (int): The user ID for whom to predict the score.\n","        item_id (int): The item ID for which to predict the score.\n","\n","        Returns:\n","        float: Predicted score.\n","        \"\"\"\n","        u = self.user_map[user_id]\n","        i = self.item_map[item_id]\n","        return np.dot(self.user_factors[u], self.item_factors[i])\n","\n","    def recommend(self, user_id, k=10):\n","        \"\"\"\n","        Recommends K items for a given user.\n","\n","        Parameters:\n","        user_id (int): The user ID for whom to generate recommendations.\n","        k (int): Number of recommendations to generate.\n","\n","        Returns:\n","        pd.DataFrame: DataFrame containing recommended movieIDs as a list for the given user.\n","        \"\"\"\n","        user_index = self.user_map[user_id]\n","        scores = np.dot(self.user_factors[user_index], self.item_factors.T)\n","        ranked_items = np.argsort(scores)[::-1]\n","\n","        recommended_items = [self.inverse_item_map[i] for i in ranked_items[:k]]\n","        return pd.DataFrame({'userID': [user_id], 'recommended_movieIDs': [recommended_items]})\n","\n","    def recommend_all_users(self, k=10):\n","        \"\"\"\n","        Recommends K items for all users in the dataset.\n","\n","        Parameters:\n","        k (int): Number of recommendations to generate for each user.\n","\n","        Returns:\n","        pd.DataFrame: DataFrame containing userID and a list of recommended movieIDs for each user.\n","        \"\"\"\n","        recommendations_list = []\n","        for user_id in tqdm(self.rating_df['userID'].unique(), desc=\"Generating recommendations for all users\"):\n","            recommendations = self.recommend(user_id, k)\n","            recommendations_list.append(recommendations)\n","\n","        return pd.concat(recommendations_list, ignore_index=True)\n"]},{"cell_type":"markdown","metadata":{"id":"8VXVVbkhp0BP"},"source":["# MostPop Model"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":1,"status":"ok","timestamp":1724107170382,"user":{"displayName":"Ehsan Naghiaei","userId":"05342714995998442181"},"user_tz":420},"id":"bdwmKUehp2TC"},"outputs":[],"source":["import pandas as pd\n","from tqdm import tqdm\n","\n","class MostPopularModel:\n","    def __init__(self, rating_df):\n","        \"\"\"\n","        Initializes the Most Popular recommendation model.\n","\n","        Parameters:\n","        rating_df (pd.DataFrame): DataFrame containing user ratings with columns 'userID', 'movieID', 'rating'.\n","        \"\"\"\n","        self.rating_df = rating_df\n","        self.movie_popularity = None\n","        self.initialize_parameters()\n","\n","    def initialize_parameters(self):\n","        \"\"\"\n","        Initializes the parameters for the most popular model.\n","        \"\"\"\n","        # Compute the popularity of each movie as the total number of ratings it has received\n","        self.movie_popularity = self.rating_df.groupby('movieID').size().sort_values(ascending=False)\n","\n","    def recommend(self, user_id, k=10):\n","        \"\"\"\n","        Recommends K most popular unseen movies for a given user.\n","\n","        Parameters:\n","        user_id (int): The user ID for whom to generate recommendations.\n","        k (int): Number of recommendations to generate.\n","\n","        Returns:\n","        pd.DataFrame: DataFrame containing recommended movieIDs as a list for the given user.\n","        \"\"\"\n","        # Get the movies the user has already seen\n","        seen_movies = self.rating_df[self.rating_df['userID'] == user_id]['movieID'].unique()\n","\n","        # Filter out seen movies from the popularity list\n","        unseen_movies = self.movie_popularity.index.difference(seen_movies)\n","\n","        # Select the top k unseen movies based on popularity\n","        top_k_movies = unseen_movies[:k]\n","\n","        return pd.DataFrame({'userID': [user_id], 'recommended_movieIDs': [top_k_movies.tolist()]})\n","\n","    def recommend_all_users(self, k=10):\n","        \"\"\"\n","        Recommends K most popular unseen movies for all users in the dataset.\n","\n","        Parameters:\n","        k (int): Number of recommendations to generate for each user.\n","\n","        Returns:\n","        pd.DataFrame: DataFrame containing userID and a list of recommended movieIDs for each user.\n","        \"\"\"\n","        recommendations_list = []\n","        for user_id in tqdm(self.rating_df['userID'].unique(), desc=\"Generating recommendations for all users\"):\n","            recommendations = self.recommend(user_id, k)\n","            recommendations_list.append(recommendations)\n","\n","        return pd.concat(recommendations_list, ignore_index=True)\n"]},{"cell_type":"markdown","metadata":{"id":"6ZjR8PtOXc4g"},"source":["# Proposed Model"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":475,"status":"ok","timestamp":1724107172077,"user":{"displayName":"Ehsan Naghiaei","userId":"05342714995998442181"},"user_tz":420},"id":"mJoYQ0GaXbW3"},"outputs":[],"source":["class MixtureBetaRecommendationModel:\n","    def __init__(self, rating_df, movie_df, attributes, lam):\n","        \"\"\"\n","        Initializes the Mixture Beta recommendation model.\n","\n","        Parameters:\n","        rating_df (pd.DataFrame): DataFrame containing user ratings with columns 'userID', 'movieID', 'like'.\n","        movie_df (pd.DataFrame): DataFrame containing movie attributes with columns 'movieID', and attribute columns.\n","        attributes (list): List of attribute columns to consider (e.g., ['genre', 'lead_actor']).\n","        \"\"\"\n","        self.rating_df = rating_df\n","        self.movie_df = movie_df\n","        self.attributes = attributes\n","        self.alpha1 = {}\n","        self.beta1 = {}\n","        self.alpha2 = {}\n","        self.beta2 = {}\n","        self.lambda_ = lam\n","        self.initialize_parameters()\n","\n","    def initialize_parameters(self):\n","        \"\"\"\n","        Initializes the alpha and beta parameters for each user-attribute pair.\n","        \"\"\"\n","        users = self.rating_df['userID'].unique()\n","        for user in tqdm(users, desc=\"Initializing parameters\"):\n","            self.alpha1[user] = {attr: {val: 1 for val in self.movie_df[attr].unique()} for attr in self.attributes}\n","            self.beta1[user] = {attr: {val: 1 for val in self.movie_df[attr].unique()} for attr in self.attributes}\n","            self.alpha2[user] = {attr: {val: 1 for val in self.movie_df[attr].unique()} for attr in self.attributes}\n","            self.beta2[user] = {attr: {val: 1 for val in self.movie_df[attr].unique()} for attr in self.attributes}\n","\n","    def update_parameters(self, train_df):\n","        \"\"\"\n","        Updates the alpha and beta parameters based on the training data.\n","\n","        Parameters:\n","        train_df (pd.DataFrame): Training DataFrame with binary ratings.\n","        \"\"\"\n","        users = train_df['userID'].unique()\n","        for user in tqdm(users, desc=\"Updating parameters\"):\n","            user_ratings = train_df[train_df['userID'] == user]\n","            for attr in self.attributes:\n","                attr_values = self.movie_df.set_index('movieID').loc[user_ratings['movieID'], attr].values\n","\n","                # Count likes and dislikes for each attribute value\n","                like_counts = {val: 0 for val in self.movie_df[attr].unique()}\n","                dislike_counts = {val: 0 for val in self.movie_df[attr].unique()}\n","\n","                for movie_id, like in zip(user_ratings['movieID'], user_ratings['like']):\n","                    attr_value = self.movie_df.set_index('movieID').loc[movie_id, attr]\n","                    if like == 1:\n","                        like_counts[attr_value] += 1\n","                    else:\n","                        dislike_counts[attr_value] += 1\n","\n","                for val in like_counts:\n","                    num_likes = like_counts[val]\n","                    num_dislikes = dislike_counts[val]\n","                    observed_outcomes, _ = self.generate_observed_outcomes(num_likes, num_dislikes)\n","\n","                    # Update using phi1_first and phi2_first sequences\n","                    prior_phi1, prior_phi2 = self.define_beta_priors(np.linspace(0, 1, 1000),\n","                                                                     self.alpha1[user][attr][val], self.beta1[user][attr][val],\n","                                                                     self.alpha2[user][attr][val], self.beta2[user][attr][val])\n","\n","                    mean_phi1_list_1, mean_phi2_list_1, posterior_phi1_1, posterior_phi2_1 = self.run_update_sequence(\n","                        np.copy(prior_phi1), np.copy(prior_phi2), observed_outcomes, self.lambda_, 'phi1_first')\n","                    mean_phi1_list_2, mean_phi2_list_2, posterior_phi1_2, posterior_phi2_2 = self.run_update_sequence(\n","                        np.copy(prior_phi1), np.copy(prior_phi2), observed_outcomes, self.lambda_, 'phi2_first')\n","\n","                    # Average results\n","                    average_mean_phi1 = [(x + y) / 2 for x, y in zip(mean_phi1_list_1, mean_phi1_list_2)]\n","                    average_mean_phi2 = [(x + y) / 2 for x, y in zip(mean_phi2_list_1, mean_phi2_list_2)]\n","                    average_posterior_phi1 = (posterior_phi1_1 + posterior_phi1_2) / 2\n","                    average_posterior_phi2 = (posterior_phi2_1 + posterior_phi2_2) / 2\n","\n","                    self.alpha1[user][attr][val] = average_mean_phi1[-1] * 1000  # Scale to match the prior updates\n","                    self.beta1[user][attr][val] = (1 - average_mean_phi1[-1]) * 1000\n","                    self.alpha2[user][attr][val] = average_mean_phi2[-1] * 1000\n","                    self.beta2[user][attr][val] = (1 - average_mean_phi2[-1]) * 1000\n","\n","    def define_beta_priors(self, phi_range, alpha1, beta1, alpha2, beta2):\n","        \"\"\"\n","        Defines the initial prior distributions for phi1 and phi2 based on Beta distributions.\n","\n","        Parameters:\n","        phi_range (np.array): The range of phi values.\n","        alpha1 (float): Alpha parameter for the Beta distribution of phi1.\n","        beta1 (float): Beta parameter for the Beta distribution of phi1.\n","        alpha2 (float): Alpha parameter for the Beta distribution of phi2.\n","        beta2 (float): Beta parameter for the Beta distribution of phi2.\n","\n","        Returns:\n","        tuple: Two numpy arrays representing the prior distributions of phi1 and phi2.\n","        \"\"\"\n","        prior_phi1 = beta.pdf(phi_range, alpha1, beta1)\n","        prior_phi2 = beta.pdf(phi_range, alpha2, beta2)\n","        return prior_phi1, prior_phi2\n","\n","    def update_distribution(self, prior_phi, phi_range, lambda_, outcome, other_phi_mean):\n","        likelihood = phi_range if outcome == 'H' else 1 - phi_range\n","        if outcome == 'H':\n","            numerator = lambda_ * likelihood + (1 - lambda_) * other_phi_mean\n","        else:\n","            numerator = lambda_ * likelihood + (1 - lambda_) * (1 - other_phi_mean)\n","\n","        updated_phi = numerator * prior_phi\n","        updated_phi /= np.sum(updated_phi)  # Normalizing\n","        return updated_phi\n","\n","    def generate_observed_outcomes(self, num_heads, num_tails):\n","        \"\"\"\n","        Generate a list of observed outcomes based on the number of heads and tails.\n","\n","        Parameters:\n","        num_heads (int): The number of heads observed.\n","        num_tails (int): The number of tails observed.\n","\n","        Returns:\n","        list: A list of observed outcomes ('H' for heads and 'T' for tails).\n","        \"\"\"\n","        observed_outcomes = []\n","        for _ in range(num_heads):\n","            observed_outcomes.append('H')\n","        for _ in range(num_tails):\n","            observed_outcomes.append('T')\n","        return observed_outcomes, f'{num_heads} heads in {num_heads + num_tails} trials'\n","\n","    def run_update_sequence(self, prior_phi1, prior_phi2, observed_outcomes, lambda_, order):\n","        phi_range = np.linspace(0, 1, 1000)\n","        mean_phi1_list = []\n","        mean_phi2_list = []\n","\n","        for outcome in observed_outcomes:\n","            if order == 'phi1_first':\n","                # Update phi1\n","                phi2_mean = np.sum(prior_phi2 * phi_range)\n","                prior_phi1 = self.update_distribution(prior_phi1, phi_range, lambda_, outcome, phi2_mean)\n","                mean_phi1 = np.sum(prior_phi1 * phi_range)\n","                mean_phi1_list.append(mean_phi1)\n","\n","                # Update phi2\n","                phi1_mean = np.sum(prior_phi1 * phi_range)\n","                prior_phi2 = self.update_distribution(prior_phi2, phi_range, 1 - lambda_, outcome, phi1_mean)\n","                mean_phi2 = np.sum(prior_phi2 * phi_range)\n","                mean_phi2_list.append(mean_phi2)\n","            elif order == 'phi2_first':\n","                # Update phi2\n","                phi1_mean = np.sum(prior_phi1 * phi_range)\n","                prior_phi2 = self.update_distribution(prior_phi2, phi_range, 1 - lambda_, outcome, phi1_mean)\n","                mean_phi2 = np.sum(prior_phi2 * phi_range)\n","                mean_phi2_list.append(mean_phi2)\n","\n","                # Update phi1\n","                phi2_mean = np.sum(prior_phi2 * phi_range)\n","                prior_phi1 = self.update_distribution(prior_phi1, phi_range, lambda_, outcome, phi2_mean)\n","                mean_phi1 = np.sum(prior_phi1 * phi_range)\n","                mean_phi1_list.append(mean_phi1)\n","\n","        return mean_phi1_list, mean_phi2_list, prior_phi1, prior_phi2\n","\n","    def recommend(self, user_id, k=10):\n","        \"\"\"\n","        Recommends K movies for a given user.\n","\n","        Parameters:\n","        user_id (int): The user ID for whom to generate recommendations.\n","        k (int): Number of recommendations to generate.\n","\n","        Returns:\n","        pd.DataFrame: DataFrame containing recommended movieIDs as a list for the given user.\n","        \"\"\"\n","        user_alpha1 = self.alpha1[user_id]\n","        user_beta1 = self.beta1[user_id]\n","        user_alpha2 = self.alpha2[user_id]\n","        user_beta2 = self.beta2[user_id]\n","\n","        attr_scores = {}\n","        for attr in self.attributes:\n","            attr_scores[attr] = {\n","                val: (user_alpha1[attr][val] / (user_alpha1[attr][val] + user_beta1[attr][val]) +\n","                      user_alpha2[attr][val] / (user_alpha2[attr][val] + user_beta2[attr][val])) / 2\n","                for val in user_alpha1[attr]\n","            }\n","\n","        # Filter out movies the user has already rated\n","        seen_movies = self.rating_df[self.rating_df['userID'] == user_id]['movieID'].unique()\n","        unseen_movies = self.movie_df[~self.movie_df['movieID'].isin(seen_movies)]\n","        # unseen_movies = self.movie_df[self.movie_df['movieID'].isin(seen_movies)]\n","\n","        movie_scores = np.ones(len(unseen_movies))\n","        for attr in self.attributes:\n","            movie_attr_values = unseen_movies[attr].map(attr_scores[attr]).values\n","            movie_scores *= movie_attr_values\n","\n","        top_k_indices = np.argsort(movie_scores)[-k:][::-1]\n","        recommendations = unseen_movies.iloc[top_k_indices]['movieID'].tolist()\n","\n","        return pd.DataFrame({'userID': [user_id], 'recommended_movieIDs': [recommendations]})\n","\n","    def recommend_all_users(self, k=10):\n","        \"\"\"\n","        Recommends K movies for all users in the dataset.\n","\n","        Parameters:\n","        k (int): Number of recommendations to generate for each user.\n","\n","        Returns:\n","        pd.DataFrame: DataFrame containing userID and a list of recommended movieIDs for each user.\n","        \"\"\"\n","        recommendations_list = []\n","        for user_id in tqdm(self.rating_df['userID'].unique(), desc=\"Generating recommendations for all users\"):\n","            recommendations = self.recommend(user_id, k)\n","            recommendations_list.append(recommendations)\n","\n","        return pd.concat(recommendations_list, ignore_index=True)"]},{"cell_type":"markdown","metadata":{"id":"_DIP_RkexDmx"},"source":["# Evaluation Pipeline"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":2,"status":"ok","timestamp":1724107172735,"user":{"displayName":"Ehsan Naghiaei","userId":"05342714995998442181"},"user_tz":420},"id":"BdvZgLzaw4JX"},"outputs":[],"source":["def evaluate_recommendations(train_df, test_df, recommendations_df, k=10):\n","    \"\"\"\n","    Evaluates the recommendations using precision, recall, and NDCG on both train and test data.\n","\n","    Parameters:\n","    train_df (pd.DataFrame): Training DataFrame containing user ratings.\n","    test_df (pd.DataFrame): Testing DataFrame containing user ratings.\n","    recommendations_df (pd.DataFrame): DataFrame containing recommendations with columns 'userID' and 'recommended_movieIDs'.\n","    k (int): Number of recommendations generated per user.\n","\n","    Returns:\n","    pd.DataFrame: DataFrame containing precision, recall, and NDCG for each user.\n","    \"\"\"\n","    def calculate_metrics(df, user_id, recommended_movies):\n","        user_ratings = df[df['userID'] == user_id]\n","        liked_movies = user_ratings[user_ratings['like'] == 1]['movieID'].tolist()\n","\n","        tp = len(set(recommended_movies) & set(liked_movies))\n","        fp = len(set(recommended_movies) - set(liked_movies))\n","        fn = len(set(liked_movies) - set(recommended_movies))\n","\n","        precision = tp / (tp + fp) if tp + fp > 0 else 0\n","        recall = tp / (tp + fn) if tp + fn > 0 else 0\n","\n","        y_true = [1 if movie in liked_movies else 0 for movie in recommended_movies]\n","        y_score = [1 for _ in range(len(recommended_movies))]\n","        ndcg = ndcg_score([y_true], [y_score]) if y_true else 0\n","\n","        return precision, recall, ndcg\n","\n","    metrics_list = []\n","\n","    for _, row in recommendations_df.iterrows():\n","        user_id = row['userID']\n","        recommended_movies = row['recommended_movieIDs']\n","\n","        train_precision, train_recall, train_ndcg = calculate_metrics(train_df, user_id, recommended_movies)\n","        test_precision, test_recall, test_ndcg = calculate_metrics(test_df, user_id, recommended_movies)\n","\n","        metrics_list.append({\n","            'userID': user_id,\n","            'train_precision': train_precision,\n","            'train_recall': train_recall,\n","            'train_ndcg': train_ndcg,\n","            'test_precision': test_precision,\n","            'test_recall': test_recall,\n","            'test_ndcg': test_ndcg\n","        })\n","\n","    metrics_df = pd.DataFrame(metrics_list)\n","\n","    print(\"Train Metrics:\")\n","    print(\"Average Precision: \", metrics_df['train_precision'].mean())\n","    print(\"Average Recall: \", metrics_df['train_recall'].mean())\n","    print(\"Average NDCG: \", metrics_df['train_ndcg'].mean())\n","\n","    print(\"\\nTest Metrics:\")\n","    print(\"Average Precision: \", metrics_df['test_precision'].mean())\n","    print(\"Average Recall: \", metrics_df['test_recall'].mean())\n","    print(\"Average NDCG: \", metrics_df['test_ndcg'].mean())\n","\n","    return metrics_df\n"]},{"cell_type":"markdown","metadata":{"id":"Se5P97h3_NMj"},"source":["# Run and Test"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":2,"status":"ok","timestamp":1724107176737,"user":{"displayName":"Ehsan Naghiaei","userId":"05342714995998442181"},"user_tz":420},"id":"PA2YTy06_Mu2"},"outputs":[],"source":["def generate_ratings(num_ratings, user_df, movie_df, randomness=0.0):\n","    \"\"\"\n","    Generates ratings for users based on their preferences and the movie catalog with added randomness.\n","\n","    Parameters:\n","    num_ratings (int): Number of ratings to generate per user.\n","    user_df (pd.DataFrame): DataFrame containing user behaviors.\n","    movie_df (pd.DataFrame): DataFrame containing the movie catalog.\n","    randomness (float): Degree of randomness in assigned ratings. 0 means no randomness, 1 means fully random.\n","\n","    Returns:\n","    pd.DataFrame: DataFrame containing the ratings with columns 'userID', 'movieID', 'rating'.\n","    \"\"\"\n","    ratings_list = []\n","\n","    for _, user in user_df.iterrows():\n","        user_id = user['userID']\n","        genre_pref_consistent = user['genre_pref']\n","        other_attr_pref_consistent = user['other_attr_pref']\n","        alpha = user['alpha']\n","        beta = user['beta']\n","\n","        # Generate inconsistent preferences by shuffling the consistent preferences\n","        genre_pref_inconsistent = genre_pref_consistent.copy()\n","        other_attr_pref_inconsistent = other_attr_pref_consistent.copy()\n","        np.random.shuffle(genre_pref_inconsistent)\n","        np.random.shuffle(other_attr_pref_inconsistent)\n","\n","        sampled_movies = movie_df.sample(n=num_ratings, replace=False)\n","\n","        for _, movie in sampled_movies.iterrows():\n","            movie_id = movie['movieID']\n","            genre = movie['genre']\n","            other_attr = movie['other_attribute']\n","\n","            # Determine the latent context (consistent or inconsistent)\n","            if np.random.rand() < randomness:\n","                # Inconsistent behavior: Use shuffled preferences\n","                genre_pref = genre_pref_inconsistent\n","                other_attr_pref = other_attr_pref_inconsistent\n","            else:\n","                # Consistent behavior: Use original preferences\n","                genre_pref = genre_pref_consistent\n","                other_attr_pref = other_attr_pref_consistent\n","\n","            # Determine the value based on user's preference order\n","            genre_value = (len(genre_pref) - genre_pref.index(genre)) / len(genre_pref)\n","            other_attr_value = (len(other_attr_pref) - other_attr_pref.index(other_attr)) / len(other_attr_pref)\n","\n","            # Cobb-Douglas value function\n","            value = (genre_value ** alpha) * (other_attr_value ** beta)\n","\n","            ratings_list.append([user_id, movie_id, value])\n","\n","    ratings_df = pd.DataFrame(ratings_list, columns=['userID', 'movieID', 'value'])\n","\n","    # Normalize values to 1-5 scale for ratings\n","    ratings_df['rating'] = 1 + round(4 * (ratings_df['value'] - ratings_df['value'].min()) / (ratings_df['value'].max() - ratings_df['value'].min()))\n","\n","    return ratings_df[['userID', 'movieID', 'rating']]\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"vUTnHiNNxFu1"},"outputs":[],"source":["# Parameters\n","num_movies = 200\n","num_users = 1000\n","num_ratings_per_user = 100\n","genres = ['comedy', 'drama', 'action', 'thriller']\n","lead_actors = ['actor1', 'actor2', 'actor3', 'actor4']\n","randomness = 0.5  # 50% randomness in ratings\n","\n","# Generate catalog and users behavior\n","movie_catalog = generate_catalog(num_movies, genres, lead_actors)\n","user_behavior = generate_users_behavior(num_users, genres, lead_actors)\n","\n","# Generate ratings with added randomness\n","ratings_df_inconsistent = generate_ratings(num_ratings_per_user, user_behavior, movie_catalog, randomness)\n","\n","# Convert ratings to binary likes/dislikes\n","binary_ratings_df = convert_to_binary_ratings(ratings_df_inconsistent)\n","\n","# Split into train and test sets\n","train_df, test_df = split_train_test(binary_ratings_df)\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":6235,"status":"ok","timestamp":1723610032767,"user":{"displayName":"Ehsan Naghiaei","userId":"05342714995998442181"},"user_tz":420},"id":"AgmUZmdq_Zxe","outputId":"83571b37-7e86-42b5-b83b-fb2d92365467"},"outputs":[],"source":["# Instantiate the model\n","model = BayesianRecommendationModel(train_df, movie_catalog, attributes=['genre', 'other_attribute'])\n","\n","\n","# Update model parameters with training data\n","model.update_parameters(train_df)\n","\n","# Generate recommendations for all users\n","recommendations_df = model.recommend_all_users(k=10)\n","\n","# Evaluate the recommendations\n","metrics_df = evaluate_recommendations(train_df, test_df, recommendations_df, k=10)\n","\n","print(recommendations_df.head())"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2391,"status":"ok","timestamp":1723491536597,"user":{"displayName":"Ehsan Naghiaei","userId":"05342714995998442181"},"user_tz":420},"id":"HwgAoJsCT1Lj","outputId":"23781d9b-642f-4aae-9fcd-a258ee1e9e57"},"outputs":[],"source":["# Instantiate the BPR model\n","bpr_model = BPRModel(train_df)\n","\n","# Train the model\n","bpr_model.train()\n","\n","# Recommend movies for a specific user\n","recommendations = bpr_model.recommend(user_id=1, k=10)\n","\n","# Recommend movies for all users\n","recommendations_df = bpr_model.recommend_all_users(k=10)\n","\n","metrics_df = evaluate_recommendations(train_df, test_df, recommendations_df, k=10)\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":66299,"status":"ok","timestamp":1723343214033,"user":{"displayName":"Ehsan Naghiaei","userId":"05342714995998442181"},"user_tz":420},"id":"KXkLpE49xeq2","outputId":"c83aed54-0b82-4278-f960-ac2b274888c3"},"outputs":[],"source":["# Instantiate the model\n","collab_model = CollaborativeFilteringModel(train_df)\n","\n","# Generate recommendations for all users\n","recommendations_df = collab_model.recommend_all_users( k=10)\n","\n","# Evaluate the recommendations\n","metrics_df = evaluate_recommendations(train_df, test_df, recommendations_df, k=10)\n","\n","print(recommendations_df.head())"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":65378,"status":"ok","timestamp":1723491735004,"user":{"displayName":"Ehsan Naghiaei","userId":"05342714995998442181"},"user_tz":420},"id":"dhb4VDK-LJsv","outputId":"af9d898c-f2cf-4b09-b962-805ee3eb2042"},"outputs":[],"source":["# Initialize the model\n","multi_attr_model = MultiAttributeUtilityModel(train_df, movie_catalog, attributes=['genre', 'other_attribute'])\n","\n","# Fit the model parameters\n","multi_attr_model.fit()\n","\n","# Generate recommendations for all users\n","recommendations_df = multi_attr_model.recommend_all_users(k=10)\n","\n","# Evaluate the recommendations\n","metrics_df = evaluate_recommendations(train_df, test_df, recommendations_df, k=10)\n","\n","print(recommendations_df.head())"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":43674,"status":"ok","timestamp":1723343507262,"user":{"displayName":"Ehsan Naghiaei","userId":"05342714995998442181"},"user_tz":420},"id":"sdqG0IgvVihQ","outputId":"01816143-9cdf-4012-bc93-6f0e72129b2c"},"outputs":[],"source":["# Instantiate the model\n","mixture_beta_model = MixtureBetaRecommendationModel(train_df, movie_catalog, attributes=['genre', 'other_attribute'], lam = 0.5)\n","\n","# Generate recommendations for all users\n","mixture_beta_model.update_parameters(ratings_df_inconsistent)\n","\n","# Generate recommendations for all users\n","recommendations_df = mixture_beta_model.recommend_all_users(k=10)\n","\n","# Evaluate the recommendations\n","metrics_df = evaluate_recommendations(train_df, test_df, recommendations_df, k=10)\n","\n","print(recommendations_df.head())"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"5Pb4e1iAViYy"},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{"id":"FTgy0L6pUZKV"},"source":["# Run for all models"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"K_NZX7frUahn"},"outputs":[],"source":["import pandas as pd\n","from itertools import product\n","\n","def run_simulations_and_save_results(num_movies_list, num_users_list, num_ratings_per_user_list, randomness_values, genres, lead_actors, output_file):\n","    # Initialize an empty DataFrame to store results\n","    all_metrics_df = pd.DataFrame()\n","\n","    # Iterate over all combinations of parameters\n","    for num_movies, num_users, num_ratings_per_user, randomness in product(num_movies_list, num_users_list, num_ratings_per_user_list, randomness_values):\n","        # Generate catalog and users behavior\n","        print(f'Running for num_movies {num_movies}, num_users {num_users}, num rating per user {num_ratings_per_user}, and randomness {randomness}')\n","        movie_catalog = generate_catalog(num_movies, genres, lead_actors)\n","        user_behavior = generate_users_behavior(num_users, genres, lead_actors)\n","\n","        # Generate ratings with added randomness\n","        ratings_df_inconsistent = generate_ratings(num_ratings_per_user, user_behavior, movie_catalog, randomness)\n","\n","        # Convert ratings to binary likes/dislikes\n","        binary_ratings_df = convert_to_binary_ratings(ratings_df_inconsistent)\n","\n","        # Split into train and test sets\n","        train_df, test_df = split_train_test(binary_ratings_df)\n","\n","        # Define and evaluate all models\n","        models = {\n","            'BayesianRecommendationModel': BayesianRecommendationModel(train_df, movie_catalog, attributes=['genre', 'other_attribute']),\n","            'CollaborativeFilteringModel': CollaborativeFilteringModel(train_df),\n","            'MultiAttributeUtilityModel': MultiAttributeUtilityModel(train_df, movie_catalog, attributes=['genre', 'other_attribute']),\n","            'MixtureBetaRecommendationModel': MixtureBetaRecommendationModel(train_df, movie_catalog, attributes=['genre', 'other_attribute'], lam=randomness),\n","            'BPRModel': BPRModel(train_df),  # Adding the BPR model\n","            'MostPopularModel': MostPopularModel(train_df)\n","        }\n","\n","        for model_name, model in models.items():\n","            print(f'running for model name {model_name}:')\n","            if model_name == 'MixtureBetaRecommendationModel':\n","                model.update_parameters(ratings_df_inconsistent)\n","            elif model_name == 'BPRModel':\n","                model.train()\n","            else:\n","                if hasattr(model, 'fit'):\n","                    model.fit()\n","                elif hasattr(model, 'update_parameters'):\n","                    model.update_parameters(train_df)\n","\n","            # Generate recommendations\n","            recommendations_df = model.recommend_all_users(k=10)\n","\n","            # Evaluate the recommendations\n","            metrics_df = evaluate_recommendations(train_df, test_df, recommendations_df, k=10)\n","            metrics_df['model_name'] = model_name\n","            metrics_df['num_movies'] = num_movies\n","            metrics_df['num_users'] = num_users\n","            metrics_df['num_ratings_per_user'] = num_ratings_per_user\n","            metrics_df['randomness'] = randomness\n","\n","            # Append the results to the all_metrics_df\n","            all_metrics_df = pd.concat([all_metrics_df, metrics_df])\n","\n","    # Save the results to a CSV file\n","    all_metrics_df.to_csv(output_file, index=False)\n","\n","    return all_metrics_df"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":19201,"status":"ok","timestamp":1723610076903,"user":{"displayName":"Ehsan Naghiaei","userId":"05342714995998442181"},"user_tz":420},"id":"wnISyzHxVbCW","outputId":"2bb653ff-189b-49fe-b29b-eb4fc65d5c27"},"outputs":[],"source":["from google.colab import drive\n","drive.mount('/content/drive')\n","\n","save_path = '/content/drive/MyDrive/Colab Notebooks/USC-research/bayesian/'\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"lxHicoVtA44k"},"outputs":[],"source":["def run_simulations_and_save_results(num_movies_list, num_users_list, num_ratings_per_user_list, randomness_values, genres, lead_actors, output_file):\n","    # Initialize an empty DataFrame to store results\n","    all_metrics_df = pd.DataFrame()\n","\n","    # Iterate over the index of the lists to match specific settings\n","    for i in range(len(num_movies_list)):\n","        # Extract the specific parameters for this run\n","        num_movies = num_movies_list[i]\n","        num_users = num_users_list[i]\n","        num_ratings_per_user = num_ratings_per_user_list[i]\n","        randomness = randomness_values[i]\n","\n","        # Calculate the data volume\n","        data_volume = num_ratings_per_user * num_users\n","\n","        # Print the current configuration\n","        print(f'Running for num_movies {num_movies}, num_users {num_users}, num rating per user {num_ratings_per_user}, randomness {randomness}, and data volume {data_volume}')\n","\n","        # Generate catalog and users behavior\n","        movie_catalog = generate_catalog(num_movies, genres, lead_actors)\n","        user_behavior = generate_users_behavior(num_users, genres, lead_actors)\n","\n","        # Generate ratings with added randomness\n","        ratings_df_inconsistent = generate_ratings(num_ratings_per_user, user_behavior, movie_catalog, randomness)\n","\n","        # Convert ratings to binary likes/dislikes\n","        binary_ratings_df = convert_to_binary_ratings(ratings_df_inconsistent)\n","\n","        # Split into train and test sets\n","        train_df, test_df = split_train_test(binary_ratings_df)\n","\n","        # Define and evaluate all models\n","        models = {\n","            'BayesianRecommendationModel': BayesianRecommendationModel(train_df, movie_catalog, attributes=['genre', 'other_attribute']),\n","            'CollaborativeFilteringModel': CollaborativeFilteringModel(train_df),\n","            'MultiAttributeUtilityModel': MultiAttributeUtilityModel(train_df, movie_catalog, attributes=['genre', 'other_attribute']),\n","            'MixtureBetaRecommendationModel': MixtureBetaRecommendationModel(train_df, movie_catalog, attributes=['genre', 'other_attribute'], lam=randomness),\n","            'BPRModel': BPRModel(train_df),  # Adding the BPR model\n","            'MostPopularModel': MostPopularModel(train_df)\n","        }\n","\n","        for model_name, model in models.items():\n","            print(f'Running for model name {model_name}:')\n","\n","            # Start the timer\n","            start_time = time.time()\n","\n","            if model_name == 'MixtureBetaRecommendationModel':\n","                model.update_parameters(ratings_df_inconsistent)\n","            elif model_name == 'BPRModel':\n","                model.train()\n","            else:\n","                if hasattr(model, 'fit'):\n","                    model.fit()\n","                elif hasattr(model, 'update_parameters'):\n","                    model.update_parameters(train_df)\n","\n","\n","            # Generate recommendations\n","            recommendations_df = model.recommend_all_users(k=10)\n","\n","            # End the timer\n","            end_time = time.time()\n","            training_time = end_time - start_time\n","            print(f'Training time for {model_name}: {training_time:.2f} seconds')\n","\n","            # Evaluate the recommendations\n","            metrics_df = evaluate_recommendations(train_df, test_df, recommendations_df, k=10)\n","            metrics_df['model_name'] = model_name\n","            metrics_df['num_movies'] = num_movies\n","            metrics_df['num_users'] = num_users\n","            metrics_df['num_ratings_per_user'] = num_ratings_per_user\n","            metrics_df['randomness'] = randomness\n","            metrics_df['training_time'] = training_time  # Add training time to the metrics\n","            metrics_df['data_volume'] = data_volume  # Add data volume to the metrics\n","\n","            # Append the results to the all_metrics_df\n","            all_metrics_df = pd.concat([all_metrics_df, metrics_df])\n","\n","    # Save the results to a CSV file\n","    all_metrics_df.to_csv(output_file, index=False)\n","\n","    return all_metrics_df"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"pa0cG6oYronu","outputId":"783968e2-5a78-4b27-e320-0dbb214c572b"},"outputs":[],"source":["# Example usage\n","randomness_values = [0.2, 0.2, 0.2, 0.2]\n","num_movies = [200, 200, 200, 200]\n","num_users = [1000, 2000, 3000, 4000, 5000]\n","num_ratings_per_user = [100, 100, 100, 100]\n","genres = ['comedy', 'drama', 'action', 'thriller']\n","lead_actors = ['actor1', 'actor2', 'actor3', 'actor4']\n","output_file = save_path + 'simulation_results_time2.csv'\n","\n","result_df = run_simulations_and_save_results(num_movies, num_users, num_ratings_per_user, randomness_values, genres, lead_actors, output_file)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"qxoKk3lBUeBw","outputId":"797652f1-d62a-474d-dbd0-f70b8535276f"},"outputs":[],"source":["# Example usage:\n","randomness_values = [0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1]\n","num_movies = [200]\n","num_users = [1000]\n","num_ratings_per_user = [100]\n","genres = ['comedy', 'drama', 'action', 'thriller']\n","lead_actors = ['actor1', 'actor2', 'actor3', 'actor4']\n","output_file = save_path + 'simulation_results2.csv'\n","\n","result_df = run_simulations_and_save_results(num_movies, num_users, num_ratings_per_user, randomness_values, genres, lead_actors, output_file)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"3exmk1DYq6Lx"},"outputs":[],"source":["# Example usage:\n","randomness_values = [0.2]\n","num_movies = [150, 200, 300, 400, 500, 600, 700, 800, 900, 1000]\n","num_users = [1000]\n","num_ratings_per_user = [100]\n","genres = ['comedy', 'drama', 'action', 'thriller']\n","lead_actors = ['actor1', 'actor2', 'actor3', 'actor4']\n","output_file = save_path + 'simulation_results_movie_catalog2.csv'\n","\n","result_df = run_simulations_and_save_results(num_movies, num_users, num_ratings_per_user, randomness_values, genres, lead_actors, output_file)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"1HgnPzdLq8ru"},"outputs":[],"source":["# Example usage:\n","randomness_values = [0.2]\n","num_movies = [200]\n","num_users = [1000]\n","num_ratings_per_user = [50, 60, 90, 120, 150, 180]\n","genres = ['comedy', 'drama', 'action', 'thriller']\n","lead_actors = ['actor1', 'actor2', 'actor3', 'actor4']\n","output_file = save_path + 'simulation_results_rating_num2.csv'\n","\n","result_df = run_simulations_and_save_results(num_movies, num_users, num_ratings_per_user, randomness_values, genres, lead_actors, output_file)"]},{"cell_type":"markdown","metadata":{"id":"UqBQGWs_kzRJ"},"source":["# Simulation Data Plots"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":14568,"status":"ok","timestamp":1724107241930,"user":{"displayName":"Ehsan Naghiaei","userId":"05342714995998442181"},"user_tz":420},"id":"BH4J8pNzzHqe","outputId":"e307b61e-35ca-49b4-bde1-3bcbedb0de55"},"outputs":[],"source":["from google.colab import drive\n","drive.mount('/content/drive')\n","\n","save_path = '/content/drive/MyDrive/Colab Notebooks/USC-research/bayesian/'"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":2,"status":"ok","timestamp":1724107241930,"user":{"displayName":"Ehsan Naghiaei","userId":"05342714995998442181"},"user_tz":420},"id":"bdtxExlI2Coc"},"outputs":[],"source":["input_path_randomness = save_path + 'simulation_results2.csv'\n","input_path_movie_size = save_path + 'simulation_results_movie_catalog2.csv'\n","input_path_rating_num = save_path + 'simulation_results_rating_num2.csv'\n","input_path_time = save_path + 'simulation_results_time2.csv'"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":547},"executionInfo":{"elapsed":3643,"status":"ok","timestamp":1724107259830,"user":{"displayName":"Ehsan Naghiaei","userId":"05342714995998442181"},"user_tz":420},"id":"yVMpahU8B1F4","outputId":"909109dc-af1a-4c4c-c7f0-583debe9ef94"},"outputs":[],"source":["# Load the data\n","result_df = pd.read_csv(input_path_time)\n","\n","# Filter the DataFrame for the specific configuration if needed (you can adjust or remove this part)\n","filtered_df = result_df\n","\n","# Group by model_name and data_volume, then calculate the average of training time\n","grouped_df = filtered_df.groupby(['model_name', 'data_volume']).mean().reset_index()\n","\n","# Define custom styles for each model, including MostPopularModel\n","model_styles = {\n","    'BayesianRecommendationModel': ('-.', 'o'),\n","    'CollaborativeFilteringModel': ('--', 's'),\n","    'MultiAttributeUtilityModel': (':', 'x'),\n","    'MixtureBetaRecommendationModel': ('-', '^'),\n","    'BPRModel': ('-', 'd'),\n","    'MostPopularModel': ('-', 'p')  # Added style for MostPopularModel\n","}\n","\n","model_palette = {\n","    'BayesianRecommendationModel': 'blue',\n","    'CollaborativeFilteringModel': 'red',\n","    'MultiAttributeUtilityModel': 'orange',\n","    'MixtureBetaRecommendationModel': 'green',\n","    'BPRModel': 'purple',\n","    'MostPopularModel': 'brown'  # Added color for MostPopularModel\n","}\n","\n","model_labels = {\n","    'BayesianRecommendationModel': 'Bayesian Model',\n","    'CollaborativeFilteringModel': 'Collaborative Filtering',\n","    'MultiAttributeUtilityModel': 'Multi-Attribute Utility',\n","    'MixtureBetaRecommendationModel': 'Mixture Bayesian Model',\n","    'BPRModel': 'BPR Model',\n","    'MostPopularModel': 'Most Popular Model'  # Added label for MostPopularModel\n","}\n","\n","# Plotting function for Training Time vs. Data Volume\n","def plot_metric(grouped_df, metric, ylabel, filename):\n","    plt.figure(figsize=(10, 6))\n","    for model_name in grouped_df['model_name'].unique():\n","        model_df = grouped_df[grouped_df['model_name'] == model_name]\n","        line_style, marker_style = model_styles[model_name]\n","        sns.lineplot(\n","            data=model_df,\n","            x='data_volume',\n","            y=metric,\n","            label=model_labels[model_name],\n","            color=model_palette[model_name],\n","            linestyle=line_style,\n","            marker=marker_style\n","        )\n","    plt.xlabel('Data Volume', fontweight='bold', fontsize=12)\n","    plt.ylabel(ylabel, fontweight='bold', fontsize=12)\n","\n","    # Update legend with bold fonts\n","    legend = plt.legend(title='Model')\n","    legend.get_frame().set_alpha(0.3)  # Set opacity to 70%\n","\n","    # Update legend and ticks to be bold\n","    legend.get_title().set_fontweight('bold')\n","    plt.xticks(fontweight='bold', fontsize=11)\n","    plt.yticks(fontweight='bold', fontsize=11)\n","\n","    plt.grid(True)\n","    plt.savefig(save_path + 'figs/' + filename, format='jpg', dpi=300)  # Save the plot as a jpg file\n","    plt.show()\n","    plt.close()\n","\n","# Plotting and saving the training time vs. data volume plot\n","plot_metric(grouped_df, 'training_time', 'Training Time (s)', 'training_time_vs_data_volume.jpg')"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"elapsed":5271,"status":"ok","timestamp":1724107280580,"user":{"displayName":"Ehsan Naghiaei","userId":"05342714995998442181"},"user_tz":420},"id":"6NpK3ubkmh0K","outputId":"8c5814bd-4b12-4811-f591-25e2830a861c"},"outputs":[],"source":["# Load the data\n","result_df = pd.read_csv(input_path_randomness)\n","\n","# Filter the DataFrame for the specific configuration\n","filtered_df = result_df[\n","    (result_df['num_movies'] == 200) &\n","    (result_df['num_users'] == 1000) &\n","    (result_df['num_ratings_per_user'] == 100)\n","]\n","\n","# Group by model_name and randomness, then calculate the average of NDCG, precision, and recall\n","grouped_df = filtered_df.groupby(['model_name', 'randomness']).mean().reset_index()\n","\n","# Define custom styles for each model, including MostPopularModel\n","model_styles = {\n","    'BayesianRecommendationModel': ('-.', 'o'),\n","    'CollaborativeFilteringModel': ('--', 's'),\n","    'MultiAttributeUtilityModel': (':', 'x'),\n","    'MixtureBetaRecommendationModel': ('-', '^'),\n","    'BPRModel': ('-', 'd'),\n","    'MostPopularModel': ('-', 'p')  # Added style for MostPopularModel\n","}\n","\n","model_palette = {\n","    'BayesianRecommendationModel': 'blue',\n","    'CollaborativeFilteringModel': 'red',\n","    'MultiAttributeUtilityModel': 'orange',\n","    'MixtureBetaRecommendationModel': 'green',\n","    'BPRModel': 'purple',\n","    'MostPopularModel': 'brown'  # Added color for MostPopularModel\n","}\n","\n","model_labels = {\n","    'BayesianRecommendationModel': 'Bayesian Model',\n","    'CollaborativeFilteringModel': 'Collaborative Filtering',\n","    'MultiAttributeUtilityModel': 'Multi-Attribute Utility',\n","    'MixtureBetaRecommendationModel': 'Mixture Bayesian Model',\n","    'BPRModel': 'BPR Model',\n","    'MostPopularModel': 'Most Popular Model'  # Added label for MostPopularModel\n","}\n","\n","# Plotting function for NDCG, Precision, and Recall with saving option\n","def plot_metric(grouped_df, metric, ylabel, filename):\n","    plt.figure(figsize=(10, 6))\n","    for model_name in grouped_df['model_name'].unique():\n","        model_df = grouped_df[grouped_df['model_name'] == model_name]\n","        line_style, marker_style = model_styles[model_name]\n","        sns.lineplot(\n","            data=model_df,\n","            x='randomness',\n","            y=metric,\n","            label=model_labels[model_name],\n","            color=model_palette[model_name],\n","            linestyle=line_style,\n","            marker=marker_style\n","        )\n","    plt.xlabel('Inconsistency Percentage', fontweight='bold', fontsize = 12)\n","    plt.ylabel(ylabel, fontweight='bold', fontsize = 12)\n","\n","    # Update legend with bold fonts\n","    legend = plt.legend(title='Model')\n","    legend.get_frame().set_alpha(0.3)  # Set opacity to 70%\n","\n","    # for text in legend.get_texts():\n","    #     text.set_fontweight('bold')\n","    legend.get_title().set_fontweight('bold')\n","\n","    # Update ticks to be bold\n","    plt.xticks(fontweight='bold', fontsize = 11)\n","    plt.yticks(fontweight='bold', fontsize = 11)\n","\n","    plt.grid(True)\n","    plt.savefig(save_path + 'figs/' + filename, format='jpg', dpi=300)  # Save the plot as a jpg file\n","    plt.show()\n","    plt.close()\n","\n","# Plotting and saving the plots\n","plot_metric(grouped_df, 'test_ndcg', 'Avg NDCG@10', 'randomness_sim_ndcg.jpg')\n","plot_metric(grouped_df, 'test_precision', 'Avg Precision@10', 'randomness_sim_precision.jpg')\n","plot_metric(grouped_df, 'test_recall', 'Avg Recall@10', 'randomness_sim_recall.jpg')\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"elapsed":4257,"status":"ok","timestamp":1724107291348,"user":{"displayName":"Ehsan Naghiaei","userId":"05342714995998442181"},"user_tz":420},"id":"NT5ddQqqtnjL","outputId":"6c0ea605-62b9-477f-ee27-a7988560c2f6"},"outputs":[],"source":["# Load the data\n","result_df = pd.read_csv(input_path_movie_size)\n","\n","# Filter the DataFrame for the specific configuration\n","filtered_df = result_df[\n","    (result_df['randomness'] == 0.2) &\n","    (result_df['num_users'] == 1000) &\n","    (result_df['num_ratings_per_user'] == 100)\n","]\n","\n","# Plotting function for NDCG, Precision, and Recall with saving option\n","def plot_metric(grouped_df, metric, ylabel, filename, xlabel):\n","    plt.figure(figsize=(10, 6))\n","    for model_name in grouped_df['model_name'].unique():\n","        model_df = grouped_df[grouped_df['model_name'] == model_name]\n","        line_style, marker_style = model_styles[model_name]\n","        sns.lineplot(\n","            data=model_df,\n","            x=xlabel,\n","            y=metric,\n","            label=model_labels[model_name],\n","            color=model_palette[model_name],\n","            linestyle=line_style,\n","            marker=marker_style\n","        )\n","    plt.xlabel('Catalog Size', fontweight = 'bold', fontsize = 12)\n","    plt.ylabel(ylabel, fontweight='bold', fontsize = 12)\n","\n","    # Update legend with bold fonts\n","    legend = plt.legend(title='Model')\n","    legend.get_frame().set_alpha(0.3)  # Set opacity to 70%\n","\n","    # for text in legend.get_texts():\n","    #     text.set_fontweight('bold')\n","    legend.get_title().set_fontweight('bold')\n","\n","    # Update ticks to be bold\n","    plt.xticks(fontweight='bold', fontsize = 11)\n","    plt.yticks(fontweight='bold', fontsize = 11)\n","\n","    plt.grid(True)\n","    plt.savefig(save_path + 'figs/' + filename, format='jpg', dpi=300)  # Save the plot as a jpg file\n","    plt.show()\n","    plt.close()\n","\n","xlabel = 'num_movies'\n","# Group by model_name and randomness, then calculate the average of NDCG, precision, and recall\n","grouped_df = filtered_df.groupby(['model_name', xlabel]).mean().reset_index()\n","\n","# Plotting and saving the plots\n","plot_metric(grouped_df, 'test_ndcg', 'Avg NDCG@10', 'num_movies_sim_ndcg.jpg', xlabel)\n","plot_metric(grouped_df, 'test_precision', 'Avg Precision@10', 'num_movies_sim_precision.jpg', xlabel)\n","plot_metric(grouped_df, 'test_recall', 'Avg Recall@10', 'num_movies_sim_recall.jpg', xlabel)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"elapsed":4096,"status":"ok","timestamp":1724107296563,"user":{"displayName":"Ehsan Naghiaei","userId":"05342714995998442181"},"user_tz":420},"id":"FKtHOuBtvDBS","outputId":"ebfc4345-674d-475e-82a0-2db771361640"},"outputs":[],"source":["# Load the data\n","result_df = pd.read_csv(input_path_rating_num)\n","\n","# Filter the DataFrame for the specific configuration\n","filtered_df = result_df[\n","    (result_df['num_movies'] == 200) &\n","    (result_df['num_users'] == 1000) &\n","    (result_df['randomness'] == 0.2)\n","]\n","\n","# Compute the sparsity measure\n","filtered_df['sparsity'] = 1 - (filtered_df['num_ratings_per_user'] / 200)\n","\n","# Plotting function for NDCG, Precision, and Recall with saving option\n","def plot_metric(grouped_df, metric, ylabel, filename, xlabel):\n","    plt.figure(figsize=(10, 6))\n","    for model_name in grouped_df['model_name'].unique():\n","        model_df = grouped_df[grouped_df['model_name'] == model_name]\n","        line_style, marker_style = model_styles[model_name]\n","        sns.lineplot(\n","            data=model_df,\n","            x=xlabel,\n","            y=metric,\n","            label=model_labels[model_name],\n","            color=model_palette[model_name],\n","            linestyle=line_style,\n","            marker=marker_style\n","        )\n","    plt.xlabel('Rating Sparsity', fontweight='bold', fontsize = 12)\n","    plt.ylabel(ylabel, fontweight='bold', fontsize = 12)\n","\n","    # Update legend with bold fonts\n","    legend = plt.legend(title='Model')\n","    legend.get_frame().set_alpha(0.3)  # Set opacity to 70%\n","\n","    # for text in legend.get_texts():\n","    #     text.set_fontweight('bold')\n","    legend.get_title().set_fontweight('bold')\n","\n","    # Update ticks to be bold\n","    plt.xticks(fontweight='bold', fontsize = 11)\n","    plt.yticks(fontweight='bold', fontsize = 11)\n","\n","    plt.grid(True)\n","    plt.savefig(save_path + 'figs/' + filename, format='jpg', dpi=300)  # Save the plot as a jpg file\n","    plt.show()\n","    plt.close()\n","\n","# Update the xlabel to sparsity\n","xlabel = 'sparsity'\n","\n","# Group by model_name and sparsity, then calculate the average of NDCG, precision, and recall\n","grouped_df = filtered_df.groupby(['model_name', xlabel]).mean().reset_index()\n","\n","# Plotting and saving the plots\n","plot_metric(grouped_df, 'test_ndcg', 'Avg NDCG@10', 'sparsity_sim_ndcg.jpg', xlabel)\n","plot_metric(grouped_df, 'test_precision', 'Avg Precision@10', 'sparsity_sim_precision.jpg', xlabel)\n","plot_metric(grouped_df, 'test_recall', 'Avg Recall@10', 'sparsity_sim_recall.jpg', xlabel)"]},{"cell_type":"markdown","metadata":{"id":"80vJzyQ2OsnO"},"source":["# Real Data"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":510,"status":"ok","timestamp":1724107500412,"user":{"displayName":"Ehsan Naghiaei","userId":"05342714995998442181"},"user_tz":420},"id":"G_bvziph7imC"},"outputs":[],"source":["def load_datasets(base_path, dataset_name):\n","    \"\"\"\n","    Loads the train, test, and category data for a given dataset.\n","\n","    Parameters:\n","    - base_path (str): The base path where the datasets are stored.\n","    - dataset_name (str): The name of the dataset (e.g., 'Yelp', 'MovieLens1M', etc.).\n","\n","    Returns:\n","    - train_df (pd.DataFrame): DataFrame containing the training data.\n","    - test_df (pd.DataFrame): DataFrame containing the test data.\n","    - category_df (pd.DataFrame): DataFrame containing the category data.\n","    \"\"\"\n","    # Construct the file paths\n","    train_path = f\"{base_path}/{dataset_name}/{dataset_name}_train.txt\"\n","    test_path = f\"{base_path}/{dataset_name}/{dataset_name}_test.txt\"\n","    category_path = f\"{base_path}/{dataset_name}/{dataset_name}_category.txt\"\n","\n","    # Load the datasets\n","    train_df = pd.read_csv(train_path, sep='\\t', header=None)  # Adjust `sep` and `header` based on your file format\n","    test_df = pd.read_csv(test_path, sep='\\t', header=None)\n","    category_df = pd.read_csv(category_path, sep=',', header=None)\n","\n","    return train_df, test_df, category_df\n"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":1,"status":"ok","timestamp":1724107501629,"user":{"displayName":"Ehsan Naghiaei","userId":"05342714995998442181"},"user_tz":420},"id":"jSKubRDlAug0"},"outputs":[],"source":["def process_all_data(train_df, test_df, category_df):\n","    \"\"\"\n","    Processes the train, test, and category DataFrames.\n","\n","    - Assigns column names to train and test DataFrames.\n","    - Filters test users not present in the training set.\n","    - Converts ratings to binary feedback based on the global mean.\n","    - Processes category data to extract the first and second genres.\n","\n","    Parameters:\n","    - train_df (pd.DataFrame): DataFrame containing the training data.\n","    - test_df (pd.DataFrame): DataFrame containing the test data.\n","    - category_df (pd.DataFrame): DataFrame containing the category data.\n","\n","    Returns:\n","    - processed_train_df (pd.DataFrame): Processed training DataFrame.\n","    - processed_test_df (pd.DataFrame): Processed test DataFrame.\n","    - processed_category_df (pd.DataFrame): Processed category DataFrame with columns 'movieID', 'genre', and 'other_attribute'.\n","    \"\"\"\n","\n","    # Step 1: Process train and test DataFrames\n","\n","    # Assign column names\n","    train_df.columns = ['userID', 'movieID', 'rating']\n","    test_df.columns = ['userID', 'movieID', 'rating']\n","\n","    # Filter out users in the test set who are not in the training set\n","    common_users = set(train_df['userID']).intersection(set(test_df['userID']))\n","    test_df = test_df[test_df['userID'].isin(common_users)]\n","\n","    # Combine train and test DataFrames to calculate the global mean\n","    combined_df = pd.concat([train_df, test_df])\n","    global_mean = combined_df['rating'].mean()\n","\n","    # Convert to binary ratings based on the global mean\n","    def convert_to_binary_ratings(rating_df, global_mean):\n","        rating_df['like'] = (rating_df['rating'] > global_mean).astype(int)\n","        return rating_df\n","\n","    # Apply the conversion to both train and test DataFrames\n","    train_df = convert_to_binary_ratings(train_df, global_mean)\n","    test_df = convert_to_binary_ratings(test_df, global_mean)\n","\n","    # Step 2: Process category DataFrame\n","\n","    # Split the genres into separate columns using iloc to select the second column\n","    genre_split = category_df.iloc[:, 1].str.split('|', expand=True)\n","\n","    # Assign the first genre to 'genre'\n","    category_df['genre'] = genre_split[0]\n","\n","    # Assign the second genre to 'other_attribute', or if it doesn't exist, use the first genre\n","    category_df['other_attribute'] = genre_split[1].fillna(genre_split[0])\n","\n","    # Create a new DataFrame with the required columns\n","    processed_category_df = category_df.iloc[:, [0, -2, -1]]\n","    processed_category_df.columns = ['movieID', 'genre', 'other_attribute']\n","\n","    # Return the processed DataFrames\n","    return train_df, test_df, processed_category_df"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":371,"status":"ok","timestamp":1724107503102,"user":{"displayName":"Ehsan Naghiaei","userId":"05342714995998442181"},"user_tz":420},"id":"zvWK6lFuC2lm"},"outputs":[],"source":["# Define and evaluate all models\n","def run_real_data(processed_train_df, processed_test_df, output_file):\n","  all_metrics_df = pd.DataFrame()\n","  models = {\n","      'BayesianRecommendationModel': BayesianRecommendationModel(processed_train_df, processed_category_df, attributes=['genre', 'other_attribute']),\n","      'CollaborativeFilteringModel': CollaborativeFilteringModel(processed_train_df),\n","      'MultiAttributeUtilityModel': MultiAttributeUtilityModel(processed_train_df, processed_category_df, attributes=['genre', 'other_attribute']),\n","      'MixtureBetaRecommendationModel': MixtureBetaRecommendationModel(processed_train_df, processed_category_df, attributes=['genre', 'other_attribute'], lam=0.2),\n","      'BPRModel': BPRModel(processed_train_df),\n","      'MostPopularModel': MostPopularModel(processed_train_df)\n","  }\n","\n","  for model_name, model in models.items():\n","      print(f'running for model name {model_name} and {dataset_name}:')\n","      if model_name == 'MixtureBetaRecommendationModel':\n","          model.update_parameters(processed_train_df)\n","      elif model_name == 'BPRModel':\n","          model.train()\n","      else:\n","          if hasattr(model, 'fit'):\n","              model.fit()\n","          elif hasattr(model, 'update_parameters'):\n","              model.update_parameters(processed_train_df)\n","\n","      # Generate recommendations\n","      recommendations_df = model.recommend_all_users(k=10)\n","\n","      # Evaluate the recommendations\n","      metrics_df = evaluate_recommendations(processed_train_df, processed_test_df, recommendations_df, k=10)\n","      metrics_df['model_name'] = model_name\n","      # Append the results to the all_metrics_df\n","      all_metrics_df = pd.concat([all_metrics_df, metrics_df])\n","\n","  # Save the results to a CSV file\n","  all_metrics_df.to_csv(output_file, index=False)\n","  return all_metrics_df"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":960,"status":"ok","timestamp":1723684140099,"user":{"displayName":"Ehsan Naghiaei","userId":"05342714995998442181"},"user_tz":420},"id":"7QRs8IY5UbEP","outputId":"8629be9e-a34a-4e4c-cf7a-df97ccb2597e"},"outputs":[],"source":["for dataset_name in datasets:\n","    print(f\"Processing {dataset_name} dataset...\")\n","\n","    train_df, test_df, category_df = load_datasets(base_path, dataset_name)\n","\n","    processed_train_df, processed_test_df, processed_category_df = process_all_data(train_df, test_df, category_df)\n","\n","    # Convert the 'rating' to binary 'like' based on the global mean of train and test combined\n","    full_rating_df = pd.concat([processed_train_df, processed_test_df], ignore_index=True)\n","\n","    # Calculate statistics\n","    # Concatenate train and test dataframes\n","    num_users = full_rating_df['userID'].nunique()\n","\n","    # Count the number of unique items in the category dataframe\n","    num_items = processed_category_df['movieID'].nunique()\n","\n","    # Count the number of unique categories\n","    num_categories = processed_category_df['genre'].nunique()\n","\n","    # Calculate the number of ratings in the full_rating_df\n","    num_ratings = len(full_rating_df)\n","\n","    # Calculate sparsity: (1 - (num_ratings / (num_users * num_items))) * 100\n","    sparsity = (1 - (num_ratings / (num_users * num_items))) * 100\n","\n","    # Print the results\n","    print(f\"Dataset: {dataset_name}\")\n","    print(f\"Number of unique users: {num_users}\")\n","    print(f\"Number of unique items: {num_items}\")\n","    print(f\"Number of unique categories: {num_categories}\")\n","    print(f\"Total number of interactions: {num_ratings}\")\n","    print(f\"Sparsity: {sparsity:.2f}%\")\n","    print(\"-\" * 40)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":424},"executionInfo":{"elapsed":579,"status":"ok","timestamp":1723683840425,"user":{"displayName":"Ehsan Naghiaei","userId":"05342714995998442181"},"user_tz":420},"id":"k9P0JjNijvx7","outputId":"dd58da8e-e859-48d1-da62-823ad0c4d24a"},"outputs":[],"source":["processed_category_df"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2213464,"status":"ok","timestamp":1723654773041,"user":{"displayName":"Ehsan Naghiaei","userId":"05342714995998442181"},"user_tz":420},"id":"GV235FCHGqj4","outputId":"7aad80f9-95df-42ab-f240-282c4127cfe7"},"outputs":[],"source":["# Data Path\n","datasets = ['MovieLens1M', 'Yelp', 'MovieLensSmall']\n","base_path = \"/content/drive/MyDrive/data\"\n","\n","for dataset_name in datasets:\n","  train_df, test_df, category_df = load_datasets(base_path, dataset_name)\n","\n","\n","  processed_train_df, processed_test_df, processed_category_df = process_all_data(train_df, test_df, category_df)\n","\n","  save_path = '/content/drive/MyDrive/Colab Notebooks/USC-research/bayesian/'\n","  output_file = save_path + f'{dataset_name}_results.csv'\n","\n","  result_df = run_real_data(processed_train_df, processed_test_df, output_file)\n"]},{"cell_type":"markdown","metadata":{"id":"Z5EwLufeSVw3"},"source":["# Real Data Plots"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":669,"status":"ok","timestamp":1724107523689,"user":{"displayName":"Ehsan Naghiaei","userId":"05342714995998442181"},"user_tz":420},"id":"6Rr-ovHL0P8F"},"outputs":[],"source":["datasets = ['MovieLens1M', 'Yelp', 'MovieLensSmall']\n","base_path = \"/content/drive/MyDrive/data\""]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"elapsed":4008,"status":"ok","timestamp":1724107529461,"user":{"displayName":"Ehsan Naghiaei","userId":"05342714995998442181"},"user_tz":420},"id":"RZhe2rH-SVC_","outputId":"c5c72036-16ef-4b5d-8fb0-98c201dd0a1a"},"outputs":[],"source":["# Initialize an empty DataFrame to store all results\n","all_results_df = pd.DataFrame()\n","\n","# Loop through each dataset and read the corresponding results\n","for dataset_name in datasets:\n","    output_file = save_path + f'{dataset_name}_results.csv'\n","    result_df = pd.read_csv(output_file)\n","    result_df['dataset_name'] = dataset_name  # Add a new column for the dataset name\n","    all_results_df = pd.concat([all_results_df, result_df], ignore_index=True)\n","\n","# Calculate the average metrics for each model and dataset\n","grouped_df = all_results_df.groupby(['dataset_name', 'model_name']).mean().reset_index()\n","\n","# Melt the DataFrame to make 'test_ndcg', 'test_precision', and 'test_recall' into a single column\n","melted_df = pd.melt(\n","    grouped_df,\n","    id_vars=['dataset_name', 'model_name'],\n","    value_vars=['test_ndcg', 'test_precision', 'test_recall'],\n","    var_name='metric',\n","    value_name='value'\n",")\n","\n","# Define custom styles for each model, including MostPopularModel\n","model_styles = {\n","    'BayesianRecommendationModel': ('-.', 'o'),\n","    'CollaborativeFilteringModel': ('--', 's'),\n","    'MultiAttributeUtilityModel': (':', 'x'),\n","    'MixtureBetaRecommendationModel': ('-', '^'),\n","    'BPRModel': ('-', 'd'),\n","    'MostPopularModel': ('-', 'p')\n","}\n","\n","model_palette = {\n","    'BayesianRecommendationModel': 'blue',\n","    'CollaborativeFilteringModel': 'red',\n","    'MultiAttributeUtilityModel': 'orange',\n","    'MixtureBetaRecommendationModel': 'green',\n","    'BPRModel': 'purple',\n","    'MostPopularModel': 'brown'\n","}\n","\n","model_labels = {\n","    'BayesianRecommendationModel': 'Bayesian Model',\n","    'CollaborativeFilteringModel': 'Collaborative Filtering',\n","    'MultiAttributeUtilityModel': 'Multi-Attribute Utility',\n","    'MixtureBetaRecommendationModel': 'Mixture Bayesian Model',\n","    'BPRModel': 'BPR Model',\n","    'MostPopularModel': 'Most Popular Model'\n","}\n","\n","# Function to create bar plots for each dataset with updated x-axis labels\n","def plot_metric_bar(melted_df, dataset_name, filename):\n","    # Mapping the metric names to more descriptive labels\n","    metric_labels = {\n","        'test_ndcg': 'Avg NDCG@10',\n","        'test_precision': 'Avg Precision@10',\n","        'test_recall': 'Avg Recall@10'\n","    }\n","\n","    plt.figure(figsize=(12, 8))\n","    sns.barplot(\n","        data=melted_df[melted_df['dataset_name'] == dataset_name],\n","        x='metric',\n","        y='value',\n","        hue='model_name',\n","        palette=model_palette\n","    )\n","\n","    # Apply the updated labels to the x-axis\n","    plt.xlabel('Metric', fontweight='bold', fontsize=12)\n","    plt.ylabel('Value', fontweight='bold', fontsize=12)\n","    # plt.title(f'Model Performance on {dataset_name}', fontweight='bold', fontsize=14)\n","\n","    # Update legend to use model labels instead of model names directly\n","    handles, labels = plt.gca().get_legend_handles_labels()\n","    labels = [model_labels[label] for label in labels]\n","    legend = plt.legend(handles, labels, title='Model', fontsize=11)\n","    legend.get_frame().set_alpha(0.7)  # Set opacity to 70%\n","\n","    # Update legend and ticks to be bold\n","    legend.get_title().set_fontweight('bold')\n","    plt.xticks(fontweight='bold', fontsize=11)\n","    plt.yticks(fontweight='bold', fontsize=11)\n","\n","    # Apply the updated x-axis labels\n","    current_labels = plt.gca().get_xticklabels()\n","    new_labels = [metric_labels[label.get_text()] for label in current_labels]\n","    plt.gca().set_xticklabels(new_labels)\n","\n","    plt.grid(True)\n","    plt.savefig(save_path + 'figs/' + filename, format='jpg', dpi=300)  # Save the plot as a jpg file\n","    plt.show()\n","    plt.close()\n","\n","\n","# Create bar plots for each dataset\n","for dataset_name in datasets:\n","    plot_metric_bar(melted_df, dataset_name, f'{dataset_name}_performance_comparison.jpg')"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":634},"executionInfo":{"elapsed":271,"status":"ok","timestamp":1723683353454,"user":{"displayName":"Ehsan Naghiaei","userId":"05342714995998442181"},"user_tz":420},"id":"bYitexIUTnUr","outputId":"ff14a161-ebb6-4d6f-bb46-a0f0e1727ffb"},"outputs":[],"source":["grouped_df"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":327,"status":"ok","timestamp":1723690105290,"user":{"displayName":"Ehsan Naghiaei","userId":"05342714995998442181"},"user_tz":420},"id":"K7QJ02dVbYA3","outputId":"08a0129f-136f-4291-eeee-5706b76ff90a"},"outputs":[],"source":["# Loop through each dataset and model in the grouped dataframe\n","for dataset_name in datasets:\n","    print(f\"Dataset: {dataset_name}\\n\")\n","    dataset_df = grouped_df[grouped_df['dataset_name'] == dataset_name]\n","\n","    for model_name in model_labels.keys():\n","        model_row = dataset_df[dataset_df['model_name'] == model_name]\n","\n","        if not model_row.empty:\n","            precision = model_row['test_precision'].values[0] * 100\n","            recall = model_row['test_recall'].values[0] * 100\n","            ndcg = model_row['test_ndcg'].values[0] * 100\n","            f1 = model_row['test_f1'].values[0] if 'test_f1' in model_row.columns else (2 * (precision * recall) / (precision + recall)) if precision + recall > 0 else 0.0\n","\n","            print(f\"{model_labels[model_name]:<25} & {precision:.4f} & {recall:.4f} & {ndcg:.4f} & {f1:.4f} \\\\\\\\\")\n","    print(\"\\hline \\n\" + \"-\" * 40 + \"\\n\")\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":605,"status":"ok","timestamp":1723690398725,"user":{"displayName":"Ehsan Naghiaei","userId":"05342714995998442181"},"user_tz":420},"id":"ae9BEovB8ycT","outputId":"36829a16-a772-468e-d433-e9ec4d3583d5"},"outputs":[],"source":["# Loop through each dataset and model in the grouped dataframe\n","for dataset_name in datasets:\n","    print(f\"Dataset: {dataset_name}\\n\")\n","    dataset_df = grouped_df[grouped_df['dataset_name'] == dataset_name]\n","\n","    # Find the best and second-best models for each metric\n","    best_precision = dataset_df['test_precision'].max()\n","    second_best_precision = dataset_df['test_precision'].nlargest(2).iloc[-1]\n","\n","    best_recall = dataset_df['test_recall'].max()\n","    second_best_recall = dataset_df['test_recall'].nlargest(2).iloc[-1]\n","\n","    best_ndcg = dataset_df['test_ndcg'].max()\n","    second_best_ndcg = dataset_df['test_ndcg'].nlargest(2).iloc[-1]\n","\n","    # Since F1 might not be precomputed, we'll calculate it for best and second-best as well\n","    dataset_df['f1_score'] = dataset_df.apply(lambda row: 200 * (row['test_precision'] * row['test_recall']) / (row['test_precision'] + row['test_recall']) if (row['test_precision'] + row['test_recall']) > 0 else 0.0, axis=1)\n","    best_f1 = dataset_df['f1_score'].max()\n","    second_best_f1 = dataset_df['f1_score'].nlargest(2).iloc[-1]\n","\n","    for model_name in model_labels.keys():\n","        model_row = dataset_df[dataset_df['model_name'] == model_name]\n","\n","        if not model_row.empty:\n","            precision = model_row['test_precision'].values[0] * 100\n","            recall = model_row['test_recall'].values[0] * 100\n","            ndcg = model_row['test_ndcg'].values[0] * 100\n","            f1 = model_row['f1_score'].values[0]  # F1 was calculated above\n","\n","            # Format precision\n","            if precision == best_precision * 100:\n","                precision_str = f\"\\\\textbf{{{precision:.4f}}}\"\n","            elif precision == second_best_precision * 100:\n","                precision_str = f\"\\\\textit{{{precision:.4f}}}\"\n","            else:\n","                precision_str = f\"{precision:.4f}\"\n","\n","            # Format recall\n","            if recall == best_recall * 100:\n","                recall_str = f\"\\\\textbf{{{recall:.4f}}}\"\n","            elif recall == second_best_recall * 100:\n","                recall_str = f\"\\\\textit{{{recall:.4f}}}\"\n","            else:\n","                recall_str = f\"{recall:.4f}\"\n","\n","            # Format NDCG\n","            if ndcg == best_ndcg * 100:\n","                ndcg_str = f\"\\\\textbf{{{ndcg:.4f}}}\"\n","            elif ndcg == second_best_ndcg * 100:\n","                ndcg_str = f\"\\\\textit{{{ndcg:.4f}}}\"\n","            else:\n","                ndcg_str = f\"{ndcg:.4f}\"\n","\n","            # Format F1\n","            if f1 == best_f1:\n","                f1_str = f\"\\\\textbf{{{f1:.4f}}}\"\n","            elif f1 == second_best_f1:\n","                f1_str = f\"\\\\textit{{{f1:.4f}}}\"\n","            else:\n","                f1_str = f\"{f1:.4f}\"\n","\n","            # Print the row\n","            print(f\"{model_labels[model_name]:<25} & {precision_str} & {recall_str} & {ndcg_str} & {f1_str} \\\\\\\\\")\n","\n","    print(\"\\hline \\n\" + \"-\" * 40 + \"\\n\")\n"]}],"metadata":{"colab":{"machine_shape":"hm","provenance":[],"toc_visible":true},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.6"}},"nbformat":4,"nbformat_minor":0}
